{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"cdflib","text":"<p>A python package to read CDF files without needing to install the CDF NASA library.</p> <p>Source: github | Archive: zenodo.</p>"},{"location":"#installing","title":"Installing","text":"<p>cdflib requires python 3 and numpy. To install run</p> <pre><code>python3 -m pip install cdflib\n</code></pre>"},{"location":"#what-is-cdflib","title":"What is cdflib?","text":"<p>cdflib is an effort to replicate the CDF libraries using a pure python implementation. This means users do not need to install the CDF NASA libraries.</p> <p>The only module you need to install is <code>numpy</code>, but there are a few things you can do with <code>astropy</code> and <code>xarray</code>.</p>"},{"location":"#what-can-cdflib-do","title":"What can cdflib do?","text":"<ul> <li>Ability to read variables and attributes from CDF files (see CDF Reading)</li> <li>Writes CDF version 3 files (see CDF Writing)</li> <li>Can convert between CDF time types (EPOCH/EPOCH16/TT2000) to other common time formats (see <code>CDF Time Conversions</code>)</li> <li>Can convert CDF files into XArray Dataset objects and vice versa, attempting to maintain ISTP compliance (see <code>Working with XArray</code>)</li> </ul>"},{"location":"cdfepoch/","title":"cdfepoch","text":"<p>There are three (3) unique epoch data types in CDF: CDF_EPOCH, CDF_EPOCH16 and CDF_TIME_TT2000.</p> <ul> <li>CDF_EPOCH is milliseconds since Year 0.</li> <li>CDF_EPOCH16 is picoseconds since Year 0.</li> <li>CDF_TIME_TT2000 (TT2000 as short) is nanoseconds since J2000 with leap seconds.</li> </ul> <p>The following two classes contain functions to convert those times into formats that are in more standard use.</p>"},{"location":"cdfepoch/#cdflib.epochs","title":"epochs","text":"<p>Classes:</p> Name Description <code>CDFepoch</code> <p>Convert between CDF-based epochs, np.datetime64, and Unix time.</p>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch","title":"CDFepoch","text":"<p>Convert between CDF-based epochs, np.datetime64, and Unix time.</p> <p>There are three (3) epoch data types in CDF:     1. CDF_EPOCH is milliseconds since Year 0 represented as a     single double (float in Python),     2. CDF_EPOCH16 is picoseconds since Year 0 represented as     2-doubles (complex in Python), and     3. CDF_TIME_TT2000 (TT2000 as short) is nanoseconds since J2000 with     leap seconds, represented by an 8-byte integer (int in Python).</p> <p>In Numpy, they are np.float64, np.complex128 and np.int64, respectively. All these epoch values can come from from CDF.varget function.</p> Example <pre><code>&gt;&gt;&gt; import cdflib\n&gt;&gt;&gt; # Convert to an epoch\n&gt;&gt;&gt; epoch = cdflib.cdfepoch.compute_epoch([2017,1,1,1,1,1,111])\n&gt;&gt;&gt; # Convert from an epoch\n&gt;&gt;&gt; time = cdflib.cdfepoch.to_datetime(epoch)  # Or pass epochs via CDF.varget.\n</code></pre> <p>Methods:</p> Name Description <code>breakdown</code> <p>Returns</p> <code>breakdown_epoch</code> <p>Calculate date and time from epochs</p> <code>breakdown_epoch16</code> <p>Calculate date and time from epochs</p> <code>breakdown_tt2000</code> <p>Breaks down the epoch(s) into UTC components.</p> <code>compute</code> <p>Computes the provided date/time components into CDF epoch value(s).</p> <code>encode</code> <p>Converts one or more epochs into UTC strings. The input epoch</p> <code>findepochrange</code> <p>Finds the record range within the start and end time from values</p> <code>parse</code> <p>Parses the provided date/time string(s) into CDF epoch value(s).</p> <code>timestamp_to_cdfepoch</code> <p>Converts a unix timestamp to CDF_EPOCH, the number of milliseconds since the year 0.</p> <code>timestamp_to_cdfepoch16</code> <p>Converts a unix timestamp to CDF_EPOCH16</p> <code>timestamp_to_tt2000</code> <p>Converts a unix timestamp to CDF_TIME_TT2000</p> <code>to_datetime</code> <p>Converts CDF epoch argument to numpy.datetime64.</p> <code>unixtime</code> <p>Converts CDF epoch argument into seconds after 1970-01-01. This method</p>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown","title":"breakdown  <code>staticmethod</code>","text":"<pre><code>breakdown(epochs: epoch_types) -&gt; ndarray\n</code></pre> <p>Returns:</p> Type Description <code>ndarray</code> <p>1D if scalar input, 2D otherwise.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef breakdown(epochs: epoch_types) -&gt; np.ndarray:\n    \"\"\"\n    Returns\n    -------\n    np.ndarray\n        1D if scalar input, 2D otherwise.\n    \"\"\"\n    epochs = np.array(epochs)\n    if epochs.dtype.type == np.int64:  # type: ignore\n        return CDFepoch.breakdown_tt2000(epochs)\n    elif epochs.dtype.type == np.float64:  # type: ignore\n        return CDFepoch.breakdown_epoch(epochs)\n    elif epochs.dtype.type == np.complex128:  # type: ignore\n        return CDFepoch.breakdown_epoch16(epochs)\n    else:\n        raise TypeError(f\"Not sure how to handle type {epochs.dtype}\")\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown_epoch","title":"breakdown_epoch  <code>staticmethod</code>","text":"<pre><code>breakdown_epoch(epochs: cdf_epoch_type) -&gt; ndarray\n</code></pre> <p>Calculate date and time from epochs</p> <p>Parameters:</p> Name Type Description Default <code>int, float, or array-like</code> <p>Single, list, tuple, or np.array of epoch values</p> required <p>Returns:</p> Name Type Description <code>components</code> <code>list</code> <p>List or array of date and time values.  The last axis contains (in order): year, month, day, hour, minute, second, and millisecond</p> Notes <p>If a bad epoch (-1.0e31) is supplied, a fill date of 9999-12-31 23:59:59 and 999 ms is returned.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef breakdown_epoch(epochs: cdf_epoch_type) -&gt; np.ndarray:\n    \"\"\"Calculate date and time from epochs\n\n    Parameters\n    ----------\n    epochs : int, float, or array-like\n        Single, list, tuple, or np.array of epoch values\n\n    Returns\n    -------\n    components : list\n        List or array of date and time values.  The last axis contains\n        (in order): year, month, day, hour, minute, second, and millisecond\n\n    Notes\n    -----\n    If a bad epoch (-1.0e31) is supplied, a fill date of\n    9999-12-31 23:59:59 and 999 ms is returned.\n\n    \"\"\"\n    # Test input and cast it as an array of floats\n    if (\n        isinstance(epochs, float)\n        or isinstance(epochs, np.float64)\n        or isinstance(epochs, list)\n        or isinstance(epochs, tuple)\n        or isinstance(epochs, np.ndarray)\n        or isinstance(epochs, int)\n    ):\n        new_epochs = np.asarray(epochs).astype(float)\n        if new_epochs.shape == ():\n            cshape: list[cdf_epoch_type] = []\n            new_epochs = np.array([epochs], dtype=float)\n        else:\n            cshape = list(new_epochs.shape)\n    else:\n        raise TypeError(\"Bad data for epochs: {:}\".format(type(epochs)))\n\n    # Initialize output to default values\n    cshape.append(7)\n    components = np.full(shape=cshape, fill_value=[9999, 12, 31, 23, 59, 59, 999])  # type: ignore\n    for i, epoch in enumerate(new_epochs):\n        # Ignore fill values and NaNs\n        if (epoch != -1.0e31) and not np.isnan(epoch):\n            esec = -epoch / 1000.0 if epoch &lt; 0.0 else epoch / 1000.0\n            date_time = CDFepoch._calc_from_julian(esec, 0.0)\n\n            ms = (epoch % 1000.0).astype(int)\n            date_time[..., 6] = int(ms) if ms.shape == () else ms\n\n            if len(components.shape) == 1:\n                components = date_time[..., :7]\n            else:\n                components[i] = date_time[..., :7]\n        elif epoch == 0:\n            components[i] = [0, 1, 1, 0, 0, 0, 0]\n\n    return np.squeeze(components)\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown_epoch(epochs)","title":"<code>epochs</code>","text":""},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown_epoch16","title":"breakdown_epoch16  <code>staticmethod</code>","text":"<pre><code>breakdown_epoch16(epochs: cdf_epoch16_type) -&gt; NDArray\n</code></pre> <p>Calculate date and time from epochs</p> <p>Parameters:</p> Name Type Description Default <code>array - like</code> <p>Single, list, tuple, or np.array of epoch values</p> required <p>Returns:</p> Name Type Description <code>components</code> <code>ndarray</code> <p>List or array of date and time values.  The last axis contains (in order): year, month, day, hour, minute, second, millisecond, microsecond, nanosecond, and picosecond</p> Notes <p>If a bad epoch (-1.0e31 for the real and imaginary components) is supplied, a fill date of 9999-12-31 23:59:59 and 999 ms, 999 us, 999 ns, and 999 ps is returned</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef breakdown_epoch16(epochs: cdf_epoch16_type) -&gt; npt.NDArray:\n    \"\"\"\n    Calculate date and time from epochs\n\n    Parameters\n    ----------\n    epochs : array-like\n        Single, list, tuple, or np.array of epoch values\n\n    Returns\n    -------\n    components : ndarray\n        List or array of date and time values.  The last axis contains\n        (in order): year, month, day, hour, minute, second, millisecond,\n        microsecond, nanosecond, and picosecond\n\n    Notes\n    -----\n    If a bad epoch (-1.0e31 for the real and imaginary components) is\n    supplied, a fill date of 9999-12-31 23:59:59 and 999 ms, 999 us,\n    999 ns, and 999 ps is returned\n\n    \"\"\"\n\n    if isinstance(epochs, (complex, np.complex128)) or isinstance(epochs, (list, tuple, np.ndarray)):\n        new_epochs = np.asarray(epochs)\n        if new_epochs.shape == ():\n            cshape: list[cdf_epoch16_type] = []\n            new_epochs = np.array([epochs])\n        else:\n            cshape = list(new_epochs.shape)\n    else:\n        raise TypeError(\"Bad data for epochs: {:}\".format(type(epochs)))\n\n    cshape.append(10)\n    components = np.full(shape=cshape, fill_value=[9999, 12, 31, 23, 59, 59, 999, 999, 999, 999])  # type: ignore\n    for i, epoch16 in enumerate(new_epochs):\n        # Ignore fill values\n        if (epoch16.real != -1.0e31) or (epoch16.imag != -1.0e31) or np.isnan(epoch16):\n            if (epoch16.imag == -1.0e30) or (epoch16.imag == -1.0e30):\n                components[i] = [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n                continue\n            esec = -epoch16.real if epoch16.real &lt; 0.0 else epoch16.real\n            efra = -epoch16.imag if epoch16.imag &lt; 0.0 else epoch16.imag\n\n            if len(components.shape) == 1:\n                components = CDFepoch._calc_from_julian(esec, efra)\n            else:\n                components[i] = CDFepoch._calc_from_julian(esec, efra)\n\n    return components\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown_epoch16(epochs)","title":"<code>epochs</code>","text":""},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown_tt2000","title":"breakdown_tt2000  <code>staticmethod</code>","text":"<pre><code>breakdown_tt2000(tt2000: cdf_tt2000_type) -&gt; ndarray\n</code></pre> <p>Breaks down the epoch(s) into UTC components.</p> <p>Calculate date and time from cdf_time_tt2000 integers</p> <p>Parameters:</p> Name Type Description Default <code>array - like</code> <p>Single, list, tuple, or np.array of tt2000 values</p> required <p>Returns:</p> Name Type Description <code>components</code> <code>ndarray</code> <p>List or array of date and time values.  The last axis contains (in order): year, month, day, hour, minute, second, millisecond, microsecond, and nanosecond</p> Notes <p>If a bad epoch is supplied, a fill date of 9999-12-31 23:59:59 and 999 ms, 999 us, and 999 ns is returned.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef breakdown_tt2000(tt2000: cdf_tt2000_type) -&gt; np.ndarray:\n    \"\"\"\n    Breaks down the epoch(s) into UTC components.\n\n    Calculate date and time from cdf_time_tt2000 integers\n\n    Parameters\n    ----------\n    tt2000 : array-like\n        Single, list, tuple, or np.array of tt2000 values\n\n    Returns\n    -------\n    components : ndarray\n        List or array of date and time values.  The last axis contains\n        (in order): year, month, day, hour, minute, second, millisecond,\n        microsecond, and nanosecond\n\n    Notes\n    -----\n    If a bad epoch is supplied, a fill date of 9999-12-31 23:59:59 and 999 ms, 999 us, and\n    999 ns is returned.\n    \"\"\"\n\n    new_tt2000 = np.atleast_1d(tt2000).astype(np.int64)\n    count = len(new_tt2000)\n    toutcs = np.zeros((9, count), dtype=int)\n    datxs = CDFepoch._LeapSecondsfromJ2000(new_tt2000)\n\n    # Do some computations on arrays to speed things up\n    post2000 = new_tt2000 &gt; 0\n    nanoSecsSinceJ2000 = new_tt2000.copy()\n    nanoSecsSinceJ2000[~post2000] += CDFepoch.T12hinNanoSecs\n    nanoSecsSinceJ2000[~post2000] -= CDFepoch.dTinNanoSecs\n\n    secsSinceJ2000 = (nanoSecsSinceJ2000 / CDFepoch.SECinNanoSecsD).astype(np.int64)\n    nansecs = (nanoSecsSinceJ2000 - (secsSinceJ2000 * CDFepoch.SECinNanoSecs)).astype(np.int64)  # type: ignore\n\n    posNanoSecs = new_tt2000 &gt; 0\n    secsSinceJ2000[posNanoSecs] -= 32\n    secsSinceJ2000[posNanoSecs] += 43200\n    nansecs[posNanoSecs] -= 184000000\n\n    negNanoSecs = nansecs &lt; 0\n    nansecs[negNanoSecs] += CDFepoch.SECinNanoSecs\n    secsSinceJ2000[negNanoSecs] -= 1\n\n    t2s = secsSinceJ2000 * CDFepoch.SECinNanoSecs + nansecs\n\n    post72: np.ndarray = datxs[:, 0] &gt; 0\n    secsSinceJ2000[post72] -= datxs[post72, 0].astype(int)\n    epochs = CDFepoch.J2000Since0AD12hSec + secsSinceJ2000\n\n    datxzero = datxs[:, 1] == 0.0\n    epochs[post72 &amp; ~datxzero] -= 1\n    xdates = CDFepoch._EPOCHbreakdownTT2000(epochs)\n\n    # If 1 second was subtracted, add 1 second back in\n    # Be careful not to go 60 or above\n    xdates[5, post72 &amp; ~datxzero] += 1\n    xdates[4, post72 &amp; ~datxzero] += np.floor(xdates[5, post72 &amp; ~datxzero] / 60.0)\n    xdates[5, post72 &amp; ~datxzero] = xdates[5, post72 &amp; ~datxzero] % 60\n\n    # Set toutcs, then loop through and correct for pre-1972\n    toutcs[:6, :] = xdates[:6, :]\n\n    for x in np.nonzero(~post72)[0]:\n        if datxs[x, 0] &lt;= 0.0:\n            # pre-1972...\n            epoch = epochs[x]\n            t2 = t2s[x]\n            t3 = new_tt2000[x]\n            nansec = nansecs[x]\n\n            xdate = np.zeros(9)\n            xdate[:6] = xdates[:, x]\n            xdate[8] = nansec\n\n            tmpNanosecs = CDFepoch.compute_tt2000(xdate)\n            if tmpNanosecs != t3:\n                dat0 = CDFepoch._LeapSecondsfromYMD(xdate[0], xdate[1], xdate[2])\n                tmpx = t2 - int(dat0 * CDFepoch.SECinNanoSecs)\n                tmpy = int(float(tmpx / CDFepoch.SECinNanoSecsD))\n                nansec = int(tmpx - tmpy * CDFepoch.SECinNanoSecs)\n            if nansec &lt; 0:\n                nansec = CDFepoch.SECinNanoSecs + nansec\n                tmpy = tmpy - 1\n                epoch = tmpy + CDFepoch.J2000Since0AD12hSec\n                xdate = np.zeros(9)\n                xdate[:6] = CDFepoch._EPOCHbreakdownTT2000(epoch)[:, 0]\n                xdate[8] = nansec\n                tmpNanosecs = CDFepoch.compute_tt2000(xdate)\n            if tmpNanosecs != t3:\n                dat0 = CDFepoch._LeapSecondsfromYMD(xdate[0], xdate[1], xdate[2])\n                tmpx = t2 - int(dat0 * CDFepoch.SECinNanoSecs)\n                tmpy = int((1.0 * tmpx) / CDFepoch.SECinNanoSecsD)\n                nansec = int(tmpx - tmpy * CDFepoch.SECinNanoSecs)\n                if nansec &lt; 0:\n                    nansec = CDFepoch.SECinNanoSecs + nansec\n                    tmpy = tmpy - 1\n                epoch = tmpy + CDFepoch.J2000Since0AD12hSec\n                xdate = np.zeros(9)\n                xdate[:6] = CDFepoch._EPOCHbreakdownTT2000(epoch)[:, 0]\n                xdate[8] = nansec\n                tmpNanosecs = CDFepoch.compute_tt2000(xdate)\n                if tmpNanosecs != t3:\n                    dat0 = CDFepoch._LeapSecondsfromYMD(xdate[0], xdate[1], xdate[2])\n                    tmpx = t2 - int(dat0 * CDFepoch.SECinNanoSecs)\n                    tmpy = int((1.0 * tmpx) / CDFepoch.SECinNanoSecsD)\n                    nansec = int(tmpx - tmpy * CDFepoch.SECinNanoSecs)\n                    if nansec &lt; 0:\n                        nansec = CDFepoch.SECinNanoSecs + nansec\n                        tmpy = tmpy - 1\n                    epoch = tmpy + CDFepoch.J2000Since0AD12hSec\n                    # One more determination\n                    xdate = CDFepoch._EPOCHbreakdownTT2000(epoch).ravel()\n            nansecs[x] = nansec\n            toutcs[:6, x] = xdate[:6]\n\n    # Finished pre-1972 correction\n    ml1 = nansecs // 1000000\n    tmp1 = nansecs - (1000000 * ml1)\n\n    overflow = ml1 &gt; 1000\n    ml1[overflow] -= 1000\n    toutcs[6, :] = ml1\n    toutcs[5, overflow] += 1\n\n    ma1 = tmp1 // 1000\n    na1 = tmp1 - 1000 * ma1\n    toutcs[7, :] = ma1\n    toutcs[8, :] = na1\n\n    # Check standard fill and pad values\n    cdf_epoch_time_tt2000 = np.atleast_2d(toutcs.T)\n    fillval_locations = np.all(cdf_epoch_time_tt2000 == [1707, 9, 22, 12, 12, 10, 961, 224, 192], axis=1)\n    cdf_epoch_time_tt2000[fillval_locations] = [9999, 12, 31, 23, 59, 59, 999, 999, 999]\n    padval_locations = np.all(cdf_epoch_time_tt2000 == [1707, 9, 22, 12, 12, 10, 961, 224, 193], axis=1)\n    cdf_epoch_time_tt2000[padval_locations] = [0, 1, 1, 0, 0, 0, 0, 0, 0]\n\n    return np.squeeze(cdf_epoch_time_tt2000)\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.breakdown_tt2000(tt2000)","title":"<code>tt2000</code>","text":""},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.compute","title":"compute  <code>staticmethod</code>","text":"<pre><code>compute(datetimes: ArrayLike) -&gt; Union[int, float, complex, NDArray]\n</code></pre> <p>Computes the provided date/time components into CDF epoch value(s).</p> <p>For CDF_EPOCH:     For computing into CDF_EPOCH value, each date/time elements should     have exactly seven (7) components, as year, month, day, hour, minute,     second and millisecond, in a list. For example:     [[2017,1,1,1,1,1,111],[2017,2,2,2,2,2,222]]     Or, call function compute_epoch directly, instead, with at least three     (3) first (up to seven) components. The last component, if     not the 7th, can be a float that can have a fraction of the unit.</p> <p>For CDF_EPOCH16:     They should have exactly ten (10) components, as year,     month, day, hour, minute, second, millisecond, microsecond, nanosecond     and picosecond, in a list. For example:     [[2017,1,1,1,1,1,123,456,789,999],[2017,2,2,2,2,2,987,654,321,999]]     Or, call function compute_epoch directly, instead, with at least three     (3) first (up to ten) components. The last component, if     not the 10th, can be a float that can have a fraction of the unit.</p> <p>For TT2000:     Each TT2000 typed date/time should have exactly nine (9) components, as     year, month, day, hour, minute, second, millisecond, microsecond,     and nanosecond, in a list.  For example:     [[2017,1,1,1,1,1,123,456,789],[2017,2,2,2,2,2,987,654,321]]     Or, call function compute_tt2000 directly, instead, with at least three     (3) first (up to nine) components. The last component, if     not the 9th, can be a float that can have a fraction of the unit.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef compute(datetimes: npt.ArrayLike) -&gt; Union[int, float, complex, npt.NDArray]:\n    \"\"\"\n    Computes the provided date/time components into CDF epoch value(s).\n\n    For CDF_EPOCH:\n        For computing into CDF_EPOCH value, each date/time elements should\n        have exactly seven (7) components, as year, month, day, hour, minute,\n        second and millisecond, in a list. For example:\n        [[2017,1,1,1,1,1,111],[2017,2,2,2,2,2,222]]\n        Or, call function compute_epoch directly, instead, with at least three\n        (3) first (up to seven) components. The last component, if\n        not the 7th, can be a float that can have a fraction of the unit.\n\n    For CDF_EPOCH16:\n        They should have exactly ten (10) components, as year,\n        month, day, hour, minute, second, millisecond, microsecond, nanosecond\n        and picosecond, in a list. For example:\n        [[2017,1,1,1,1,1,123,456,789,999],[2017,2,2,2,2,2,987,654,321,999]]\n        Or, call function compute_epoch directly, instead, with at least three\n        (3) first (up to ten) components. The last component, if\n        not the 10th, can be a float that can have a fraction of the unit.\n\n    For TT2000:\n        Each TT2000 typed date/time should have exactly nine (9) components, as\n        year, month, day, hour, minute, second, millisecond, microsecond,\n        and nanosecond, in a list.  For example:\n        [[2017,1,1,1,1,1,123,456,789],[2017,2,2,2,2,2,987,654,321]]\n        Or, call function compute_tt2000 directly, instead, with at least three\n        (3) first (up to nine) components. The last component, if\n        not the 9th, can be a float that can have a fraction of the unit.\n    \"\"\"\n\n    if not isinstance(datetimes, (list, tuple, np.ndarray)):\n        raise TypeError(\"datetime must be in list form\")\n\n    datetimes = np.atleast_2d(datetimes)\n    items = datetimes.shape[1]  # type: ignore\n\n    if items == 7:\n        return _squeeze_or_scalar_real(CDFepoch.compute_epoch(datetimes))\n    elif items == 10:\n        return _squeeze_or_scalar_complex(CDFepoch.compute_epoch16(datetimes))\n    elif items == 9:\n        return _squeeze_or_scalar_real(CDFepoch.compute_tt2000(datetimes))\n    else:\n        raise TypeError(\"Unknown input\")\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.encode","title":"encode  <code>staticmethod</code>","text":"<pre><code>encode(epochs: epoch_types, iso_8601: bool = True) -&gt; encoded_type\n</code></pre> <p>Converts one or more epochs into UTC strings. The input epoch format is deduced from the argument type.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_types</code> <p>One or more ECD epochs in one of three formats: 1. CDF_EPOCH: The input should be either a float or list of floats (in numpy, a np.float64 or a np.ndarray of np.float64) 2. CDF_EPOCH16: The input should be either a complex or list of complex(in numpy, a np.complex128 or a np.ndarray of np.complex128) 3. TT2000: The input should be either a int or list of ints (in numpy, a np.int64 or a np.ndarray of np.int64)</p> required <code>bool</code> <pre><code>The return time format. If ISO 8601 is True, the format is,\nfor example, 2008-02-02T06:08:10.10.012014016, otherwise\nthe format is 02-Feb-2008 06:08:10.012.014.016.\n</code></pre> <code>True</code> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef encode(epochs: epoch_types, iso_8601: bool = True) -&gt; encoded_type:\n    \"\"\"\n    Converts one or more epochs into UTC strings. The input epoch\n    format is deduced from the argument type.\n\n    Parameters\n    ----------\n    epochs: int, float, list, complex\n        One or more ECD epochs in one of three formats:\n        1. CDF_EPOCH: The input should be either a float or list of floats\n        (in numpy, a np.float64 or a np.ndarray of np.float64)\n        2. CDF_EPOCH16: The input should be either a complex or list of\n        complex(in numpy, a np.complex128 or a np.ndarray of np.complex128)\n        3. TT2000: The input should be either a int or list of ints\n        (in numpy, a np.int64 or a np.ndarray of np.int64)\n\n    iso_8601: bool\n            The return time format. If ISO 8601 is True, the format is,\n            for example, 2008-02-02T06:08:10.10.012014016, otherwise\n            the format is 02-Feb-2008 06:08:10.012.014.016.\n\n    \"\"\"\n    epochs = np.array(epochs)\n    if epochs.dtype == np.int64:\n        return CDFepoch.encode_tt2000(epochs, iso_8601)\n    elif epochs.dtype == np.float64:\n        return CDFepoch.encode_epoch(epochs, iso_8601)\n    elif epochs.dtype == np.complex128:\n        return CDFepoch.encode_epoch16(epochs, iso_8601)\n    else:\n        raise TypeError(f\"Not sure how to handle type {epochs.dtype}\")\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.encode(epochs)","title":"<code>epochs</code>","text":""},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.encode(iso_8601)","title":"<code>iso_8601</code>","text":""},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.findepochrange","title":"findepochrange  <code>staticmethod</code>","text":"<pre><code>findepochrange(epochs: epochs_type, starttime: Optional[epoch_types] = None, endtime: Optional[epoch_types] = None) -&gt; ndarray\n</code></pre> <p>Finds the record range within the start and end time from values of a CDF epoch data type. It returns a list of record numbers. If the start time is not provided, then it is assumed to be the minimum possible value. If the end time is not provided, then the maximum possible value is assumed. The epoch is assumed to be in the chronological order. The start and end times should have the proper number of date/time components, corresponding to the epoch's data type.</p> <p>The start/end times should be in either be in epoch units, or in the list format described in \"compute_epoch/epoch16/tt2000\" section.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef findepochrange(\n    epochs: epochs_type, starttime: Optional[epoch_types] = None, endtime: Optional[epoch_types] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Finds the record range within the start and end time from values\n    of a CDF epoch data type. It returns a list of record numbers.\n    If the start time is not provided, then it is\n    assumed to be the minimum possible value. If the end time is not\n    provided, then the maximum possible value is assumed. The epoch is\n    assumed to be in the chronological order. The start and end times\n    should have the proper number of date/time components, corresponding\n    to the epoch's data type.\n\n    The start/end times should be in either be in epoch units, or in the list\n    format described in \"compute_epoch/epoch16/tt2000\" section.\n    \"\"\"\n    epochs = np.array(epochs)\n    if epochs.dtype == np.int64:\n        return CDFepoch.epochrange_tt2000(epochs, starttime, endtime)\n    elif epochs.dtype == np.float64:\n        return CDFepoch.epochrange_epoch(epochs, starttime, endtime)\n    elif epochs.dtype == np.complex128:\n        return CDFepoch.epochrange_epoch16(epochs, starttime, endtime)\n    else:\n        raise TypeError(\"Bad input\")\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.parse","title":"parse  <code>staticmethod</code>","text":"<pre><code>parse(value: Union[str, Tuple[str, ...], List[str]]) -&gt; ndarray\n</code></pre> <p>Parses the provided date/time string(s) into CDF epoch value(s).</p> <p>For CDF_EPOCH:     The string has to be in the form of 'dd-mmm-yyyy hhss.xxx' or     'yyyy-mm-ddThhss.xxx' (in iso_8601). The string is the output     from encode function.</p> <p>For CDF_EPOCH16:     The string has to be in the form of     'dd-mmm-yyyy hhss.mmm.uuu.nnn.ppp' or     'yyyy-mm-ddThhss.mmmuuunnnppp' (in iso_8601). The string is     the output from encode function.</p> <p>For TT2000:     The string has to be in the form of     'dd-mmm-yyyy hhss.mmm.uuu.nnn' or     'yyyy-mm-ddThhss.mmmuuunnn' (in iso_8601). The string is     the output from encode function.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef parse(value: Union[str, Tuple[str, ...], List[str]]) -&gt; np.ndarray:\n    \"\"\"\n    Parses the provided date/time string(s) into CDF epoch value(s).\n\n    For CDF_EPOCH:\n        The string has to be in the form of 'dd-mmm-yyyy hh:mm:ss.xxx' or\n        'yyyy-mm-ddThh:mm:ss.xxx' (in iso_8601). The string is the output\n        from encode function.\n\n    For CDF_EPOCH16:\n        The string has to be in the form of\n        'dd-mmm-yyyy hh:mm:ss.mmm.uuu.nnn.ppp' or\n        'yyyy-mm-ddThh:mm:ss.mmmuuunnnppp' (in iso_8601). The string is\n        the output from encode function.\n\n    For TT2000:\n        The string has to be in the form of\n        'dd-mmm-yyyy hh:mm:ss.mmm.uuu.nnn' or\n        'yyyy-mm-ddThh:mm:ss.mmmuuunnn' (in iso_8601). The string is\n        the output from encode function.\n    \"\"\"\n    if isinstance(value, (list, tuple)) and not isinstance(value[0], str):\n        raise TypeError(\"should be a string or a list of string\")\n\n    elif not isinstance(value, (list, tuple, str)):\n        raise TypeError(\"Invalid value... should be a string or a list of string\")\n    else:\n        if isinstance(value, (list, tuple)):\n            num = len(value)\n            epochs = []\n            for x in range(num):\n                epochs.append(CDFepoch._parse_epoch(value[x]))\n            return np.squeeze(epochs)\n        else:\n            return np.squeeze(CDFepoch._parse_epoch(value))\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.timestamp_to_cdfepoch","title":"timestamp_to_cdfepoch  <code>staticmethod</code>","text":"<pre><code>timestamp_to_cdfepoch(unixtime_data: ArrayLike) -&gt; ndarray\n</code></pre> <p>Converts a unix timestamp to CDF_EPOCH, the number of milliseconds since the year 0.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef timestamp_to_cdfepoch(unixtime_data: npt.ArrayLike) -&gt; np.ndarray:\n    \"\"\"\n    Converts a unix timestamp to CDF_EPOCH, the number of milliseconds since the year 0.\n    \"\"\"\n    # Make sure the object is iterable.  Sometimes numpy arrays claim to be iterable when they aren't.\n    times = np.atleast_1d(unixtime_data)\n\n    cdf_time_data = []\n    for ud in times:\n        if not np.isnan(ud):\n            dt = np.datetime64(int(ud * 1000), \"ms\")\n            dt_item: datetime.datetime = dt.item()\n            dt_to_convert = [\n                dt_item.year,\n                dt_item.month,\n                dt_item.day,\n                dt_item.hour,\n                dt_item.minute,\n                dt_item.second,\n                int(dt_item.microsecond / 1000),\n            ]\n            converted_data = CDFepoch.compute(dt_to_convert)\n        else:\n            converted_data = np.nan\n        cdf_time_data.append(converted_data)\n\n    return np.array(cdf_time_data)\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.timestamp_to_cdfepoch16","title":"timestamp_to_cdfepoch16  <code>staticmethod</code>","text":"<pre><code>timestamp_to_cdfepoch16(unixtime_data: ArrayLike) -&gt; ndarray\n</code></pre> <p>Converts a unix timestamp to CDF_EPOCH16</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef timestamp_to_cdfepoch16(unixtime_data: npt.ArrayLike) -&gt; np.ndarray:\n    \"\"\"\n    Converts a unix timestamp to CDF_EPOCH16\n    \"\"\"\n    # Make sure the object is iterable.  Sometimes numpy arrays claim to be iterable when they aren't.\n    times = np.atleast_1d(unixtime_data)\n\n    cdf_time_data = []\n    for ud in times:\n        if not np.isnan(ud):\n            dt = np.datetime64(int(ud * 1000000), \"us\")\n            dt_item: datetime.datetime = dt.item()\n            dt_to_convert = [\n                dt_item.year,\n                dt_item.month,\n                dt_item.day,\n                dt_item.hour,\n                dt_item.minute,\n                dt_item.second,\n                int(dt_item.microsecond / 1000),\n                int(dt_item.microsecond % 1000),\n                0,\n                0,\n            ]\n            converted_data = CDFepoch.compute(dt_to_convert)\n        else:\n            converted_data = np.nan\n        cdf_time_data.append(converted_data)\n\n    return np.array(cdf_time_data)\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.timestamp_to_tt2000","title":"timestamp_to_tt2000  <code>staticmethod</code>","text":"<pre><code>timestamp_to_tt2000(unixtime_data: ArrayLike) -&gt; ndarray\n</code></pre> <p>Converts a unix timestamp to CDF_TIME_TT2000</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef timestamp_to_tt2000(unixtime_data: npt.ArrayLike) -&gt; np.ndarray:\n    \"\"\"\n    Converts a unix timestamp to CDF_TIME_TT2000\n    \"\"\"\n    # Make sure the object is iterable.  Sometimes numpy arrays claim to be iterable when they aren't.\n    times = np.atleast_1d(unixtime_data)\n\n    cdf_time_data = []\n    for ud in times:\n        if not np.isnan(ud):\n            dt = np.datetime64(int(ud * 1000000), \"us\")\n            dt_item: datetime.datetime = dt.item()\n            dt_to_convert = [\n                dt_item.year,\n                dt_item.month,\n                dt_item.day,\n                dt_item.hour,\n                dt_item.minute,\n                dt_item.second,\n                int(dt_item.microsecond / 1000),\n                int(dt_item.microsecond % 1000),\n                0,\n            ]\n            converted_data = CDFepoch.compute(dt_to_convert)\n        else:\n            converted_data = np.nan\n        cdf_time_data.append(converted_data)\n\n    return np.array(cdf_time_data)\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.to_datetime","title":"to_datetime  <code>classmethod</code>","text":"<pre><code>to_datetime(cdf_time: epoch_types) -&gt; NDArray[datetime64]\n</code></pre> <p>Converts CDF epoch argument to numpy.datetime64.</p> <p>Parameters:     cdf_time: NumPy scalar/arrays to convert. np.int64 will be converted to cdf_tt2000, np.complex128 will be converted to cdf_epoch16, and floats will be converted to cdf_epoch.</p> <p>Notes:     Because of datetime64 limitations, CDF_EPOCH16 precision is only kept to the nearest nanosecond.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@classmethod\ndef to_datetime(cls, cdf_time: epoch_types) -&gt; npt.NDArray[np.datetime64]:\n    \"\"\"\n    Converts CDF epoch argument to numpy.datetime64.\n\n    Parameters:\n        cdf_time: NumPy scalar/arrays to convert. np.int64 will be converted to cdf_tt2000, np.complex128 will be converted to cdf_epoch16, and floats will be converted to cdf_epoch.\n\n    Notes:\n        Because of datetime64 limitations, CDF_EPOCH16 precision is only kept to the nearest nanosecond.\n\n    \"\"\"\n    times = cls.breakdown(cdf_time)\n    times = np.atleast_2d(times)\n\n    fillval_locations = np.all((times[:, 0:7] == [9999, 12, 31, 23, 59, 59, 999]), axis=1)\n    padval_locations = np.all((times[:, 0:7] == [0, 1, 1, 0, 0, 0, 0]), axis=1)\n    nan_locations = np.logical_or(fillval_locations, padval_locations)\n    return cls._compose_date(nan_locations, *times.T[:9]).astype(\"datetime64[ns]\")\n</code></pre>"},{"location":"cdfepoch/#cdflib.epochs.CDFepoch.unixtime","title":"unixtime  <code>staticmethod</code>","text":"<pre><code>unixtime(cdf_time: ArrayLike) -&gt; Union[float, NDArray]\n</code></pre> <p>Converts CDF epoch argument into seconds after 1970-01-01. This method converts a scalar, or array-like. Precision is only kept to the nearest microsecond.</p> Source code in <code>cdflib/epochs.py</code> <pre><code>@staticmethod\ndef unixtime(cdf_time: npt.ArrayLike) -&gt; Union[float, npt.NDArray]:\n    \"\"\"\n    Converts CDF epoch argument into seconds after 1970-01-01. This method\n    converts a scalar, or array-like. Precision is only kept to the\n    nearest microsecond.\n    \"\"\"\n    cdf_time = np.atleast_1d(cdf_time)\n    time_list = np.atleast_2d(CDFepoch.breakdown(cdf_time))\n\n    unixtime = []\n    utc = datetime.timezone(datetime.timedelta())\n    for t in time_list:\n        date: List[int] = [0] * 7\n        for i in range(0, len(t)):\n            if i &gt; 7:\n                continue\n            elif i == 6:\n                date[i] = 1000 * t[i]\n            elif i == 7:\n                date[i - 1] += t[i]\n            else:\n                date[i] = t[i]\n        unixtime.append(\n            datetime.datetime(date[0], date[1], date[2], date[3], date[4], date[5], date[6], tzinfo=utc).timestamp()\n        )\n    return _squeeze_or_scalar_real(unixtime)\n</code></pre>"},{"location":"cdfread/","title":"cdfread","text":""},{"location":"cdfread/#cdflib.cdfread","title":"cdfread","text":"<p>Classes:</p> Name Description <code>CDF</code> <p>Read a CDF file into the CDF object. This object contains methods to load</p>"},{"location":"cdfread/#cdflib.cdfread.CDF","title":"CDF","text":"<pre><code>CDF(path: Union[str, Path], validate: bool = False, string_encoding: str = 'ascii', s3_read_method: int = 1)\n</code></pre> <p>Read a CDF file into the CDF object. This object contains methods to load the cdf file information, variable names, and values.</p> Example <pre><code>&gt;&gt;&gt; import cdflib\n&gt;&gt;&gt; cdf_file = cdflib.CDF('/path/to/cdf_file.cdf')\n&gt;&gt;&gt; cdf_file.cdf_info()\n&gt;&gt;&gt; x = cdf_file.varget(\"NameOfVariable\", startrec=0, endrec=150)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>(Path, str)</code> <p>Path to CDF file.  This can be a link to a file in an S3 bucket as well.</p> required <code>bool</code> <p>If True, validate the MD5 checksum of the CDF file.</p> <code>False</code> <code>str</code> <p>The encoding used to read strings. Defaults to 'ascii', which is what the CDF internal format description prescribes as the encoding for character strings. Other encodings may have been used to create files however, and this keyword argument gives users the flexibility to read those files.</p> <code>'ascii'</code> <code>int</code> <p>If the user is specifying a file that lives within an AWS S3 bucket, this variable defines how the file is read in.  The choices are: - 1 will read the file into memory to load in memory) - 2 will download the file to a tmp directory - 3 reads the file in chunks directly from S3 over https</p> <code>1</code> Notes <p>An open file handle to the CDF file remains whilst a CDF object is live. It is automatically cleaned up with the CDF instance is deleted.</p> <p>Methods:</p> Name Description <code>attget</code> <p>Returns the value of the attribute at the entry number provided.</p> <code>attinq</code> <p>Get attribute information.</p> <code>cdf_info</code> <p>Returns basic CDF information.</p> <code>globalattsget</code> <p>Gets all global attributes.</p> <code>varattsget</code> <p>Gets all variable attributes.</p> <code>varget</code> <p>Returns the variable data.</p> <code>varinq</code> <p>Get basic variable information.</p> Source code in <code>cdflib/cdfread.py</code> <pre><code>def __init__(self, path: Union[str, Path], validate: bool = False, string_encoding: str = \"ascii\", s3_read_method: int = 1):\n    \"\"\"\n    Parameters\n    ----------\n    path : Path, str\n        Path to CDF file.  This can be a link to a file in an S3 bucket as well.\n    validate : bool, optional\n        If True, validate the MD5 checksum of the CDF file.\n    string_encoding : str, optional\n        The encoding used to read strings. Defaults to 'ascii', which is what\n        the CDF internal format description prescribes as the encoding for\n        character strings. Other encodings may have been used to create files\n        however, and this keyword argument gives users the flexibility to read\n        those files.\n    s3_read_method: int, optional\n        If the user is specifying a file that lives within an AWS S3 bucket, this variable\n        defines how the file is read in.  The choices are:\n        - 1 will read the file into memory to load in memory)\n        - 2 will download the file to a tmp directory\n        - 3 reads the file in chunks directly from S3 over https\n\n    Notes\n    -----\n    An open file handle to the CDF file remains whilst a CDF object is live.\n    It is automatically cleaned up with the CDF instance is deleted.\n    \"\"\"\n    if isinstance(path, Path):\n        fname = path.absolute().as_posix()\n    else:\n        fname = path\n\n    self.file: Union[str, Path]\n    if fname.startswith(\"s3://\"):\n        # later put in s3 'does it exist' checker\n        self.ftype = \"s3\"\n        self.file = fname  # path for files, fname for urls and S3\n    elif fname.startswith(\"http://\") or fname.startswith(\"https://\"):\n        # later put in url 404 'does it exist' checker\n        self.ftype = \"url\"\n        self.file = fname  # path for files, fname for urls and S3\n    else:\n        self.ftype = \"file\"\n        path = Path(path).resolve().expanduser()\n        if not path.is_file():\n            path = path.with_suffix(\".cdf\")\n            if not path.is_file():\n                raise FileNotFoundError(f\"{path} not found\")\n        self.file = path  # path for files, fname for urls and S3\n        self.file = path\n\n    self.string_encoding = string_encoding\n\n    self._f = self._file_or_url_or_s3_handler(str(self.file), self.ftype, s3_read_method)\n    magic_number = self._f.read(4).hex()\n    compressed_bool = self._f.read(4).hex()\n\n    if magic_number not in (\"cdf30001\", \"cdf26002\", \"0000ffff\"):\n        raise OSError(f\"{path} is not a CDF file or a non-supported CDF!\")\n\n    self.cdfversion = 3 if magic_number == \"cdf30001\" else 2\n\n    self._compressed = not (compressed_bool == \"0000ffff\")\n    self.compressed_file = None\n    self.temp_file: Optional[Path] = None\n\n    if self._compressed:\n        if self.ftype == \"url\" or self.ftype == \"s3\":\n            if s3_read_method == 3:\n                # extra step, read entire file\n                self._f.seek(0)\n                self._f = s3_fetchall(self._f.fhandle)  # type: ignore\n            self._unstream_file(self._f)\n            path = self.file\n        self._uncompress_file()\n        if self.temp_file is None:\n            raise OSError(\"Decompression was unsuccessful.  Only GZIP compression is currently supported.\")\n\n        self.compressed_file = self.file\n        self.file = self.temp_file\n        self._f.close()\n        self._f = self.file.open(\"rb\")\n        self.ftype = \"file\"\n\n    if self.cdfversion == 3:\n        cdr_info, foffs = self._read_cdr(8)\n        gdr_info = self._read_gdr(foffs)\n    else:\n        cdr_info, foffs = self._read_cdr2(8)\n        gdr_info = self._read_gdr2(foffs)\n\n    if cdr_info.md5 and validate:\n        if not self._md5_validation():\n            raise OSError(\"This file fails the md5 checksum.\")\n\n    if not cdr_info.format_:\n        raise OSError(\"This package does not support multi-format CDF\")\n\n    if cdr_info.encoding in (3, 14, 15):\n        raise OSError(\"This package does not support CDFs with this \" + self._encoding_token(cdr_info.encoding) + \" encoding\")\n\n    # SET GLOBAL VARIABLES\n    self._post25 = cdr_info.post25\n    self._version = cdr_info.version\n    self._encoding = cdr_info.encoding\n    self._majority = self._major_token(cdr_info.majority)\n    self._copyright = cdr_info.copyright_\n    self._md5 = cdr_info.md5\n    self._first_zvariable = gdr_info.first_zvariable\n    self._first_rvariable = gdr_info.first_rvariable\n    self._first_adr = gdr_info.first_adr\n    self._num_zvariable = gdr_info.num_zvariables\n    self._num_rvariable = gdr_info.num_rvariables\n    self._rvariables_num_dims = gdr_info.rvariables_num_dims\n    self._rvariables_dim_sizes = gdr_info.rvariables_dim_sizes\n    self._num_att = gdr_info.num_attributes\n    self._num_rdim = gdr_info.rvariables_num_dims\n    self._rdim_sizes = gdr_info.rvariables_dim_sizes\n    if self.cdfversion == 3:\n        self._leap_second_updated = gdr_info.leapsecond_updated\n\n    if self.compressed_file is not None:\n        self.compressed_file = None\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF(path)","title":"<code>path</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF(validate)","title":"<code>validate</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF(string_encoding)","title":"<code>string_encoding</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF(s3_read_method)","title":"<code>s3_read_method</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.attget","title":"attget","text":"<pre><code>attget(attribute: Union[str, int], entry: Optional[Union[str, int]] = None) -&gt; AttData\n</code></pre> <p>Returns the value of the attribute at the entry number provided.</p> <p>A variable name can be used instead of its corresponding entry number.</p> <p>Parameters:</p> Name Type Description Default <code>(str, int)</code> <p>Attribute name or number to get.</p> required <code>int</code> <code>None</code> <p>Returns:</p> Type Description <code>AttData</code> Source code in <code>cdflib/cdfread.py</code> <pre><code>def attget(self, attribute: Union[str, int], entry: Optional[Union[str, int]] = None) -&gt; AttData:\n    \"\"\"\n    Returns the value of the attribute at the entry number provided.\n\n    A variable name can be used instead of its corresponding\n    entry number.\n\n    Parameters\n    ----------\n    attribute : str, int\n        Attribute name or number to get.\n    entry : int, optional\n\n    Returns\n    -------\n    AttData\n    \"\"\"\n    # Starting position\n    position = self._first_adr\n\n    # Get Correct ADR\n    adr_info = None\n    if isinstance(attribute, str):\n        for _ in range(0, self._num_att):\n            name, next_adr = self._read_adr_fast(position)\n            if name.strip().lower() == attribute.strip().lower():\n                adr_info = self._read_adr(position)\n                if isinstance(entry, str) and adr_info.scope == 1:\n                    # If the user has specified a string entry, they are obviously looking for a variable attribute.\n                    # Filter out any global attributes that may have the same name.\n                    adr_info = None\n                    position = next_adr\n                    continue\n                break\n            else:\n                position = next_adr\n\n        if adr_info is None:\n            raise KeyError(f\"No attribute {attribute} for entry {entry}\")\n\n    elif isinstance(attribute, int):\n        if (attribute &lt; 0) or (attribute &gt; self._num_att):\n            raise KeyError(f\"No attribute {attribute}\")\n        if not isinstance(entry, int):\n            raise TypeError(f\"{entry} has to be a number.\")\n\n        for _ in range(0, attribute):\n            name, next_adr = self._read_adr_fast(position)\n            position = next_adr\n        adr_info = self._read_adr(position)\n    else:\n        raise ValueError(\"Please set attribute keyword equal to \" \"the name or number of an attribute\")\n\n    # Find the correct entry from the \"entry\" variable\n    if adr_info.scope == 1:\n        if not isinstance(entry, int):\n            raise ValueError('\"entry\" must be an integer')\n        num_entry_string = \"num_gr_entry\"\n        first_entry_string = \"first_gr_entry\"\n        max_entry_string = \"max_gr_entry\"\n        entry_num = entry\n    else:\n        var_num = -1\n        zvar = False\n        if isinstance(entry, str):\n            # a zVariable?\n            positionx = self._first_zvariable\n            for x in range(0, self._num_zvariable):\n                name, vdr_next = self._read_vdr_fast(positionx)\n                if name.strip().lower() == entry.strip().lower():\n                    var_num = x\n                    zvar = True\n                    break\n                positionx = vdr_next\n            if var_num == -1:\n                # a rVariable?\n                positionx = self._first_rvariable\n                for x in range(0, self._num_rvariable):\n                    name, vdr_next = self._read_vdr_fast(positionx)\n                    if name.strip().lower() == entry.strip().lower():\n                        var_num = x\n                        break\n                    positionx = vdr_next\n            if var_num == -1:\n                raise ValueError(f\"No variable by this name: {entry}\")\n            entry_num = var_num\n        else:\n            if self._num_zvariable &gt; 0 and self._num_rvariable &gt; 0:\n                raise ValueError(\"This CDF has both r and z variables. \" \"Use variable name instead\")\n            if self._num_zvariable &gt; 0:\n                zvar = True\n            entry_num = entry\n        if zvar:\n            num_entry_string = \"num_z_entry\"\n            first_entry_string = \"first_z_entry\"\n            max_entry_string = \"max_z_entry\"\n        else:\n            num_entry_string = \"num_gr_entry\"\n            first_entry_string = \"first_gr_entry\"\n            max_entry_string = \"max_gr_entry\"\n    if entry_num &gt; getattr(adr_info, max_entry_string):\n        raise ValueError(\"The entry does not exist\")\n    return self._get_attdata(adr_info, entry_num, getattr(adr_info, num_entry_string), getattr(adr_info, first_entry_string))\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF.attget(attribute)","title":"<code>attribute</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.attget(entry)","title":"<code>entry</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.attinq","title":"attinq","text":"<pre><code>attinq(attribute: Union[str, int]) -&gt; ADRInfo\n</code></pre> <p>Get attribute information.</p> <p>Parameters:</p> Name Type Description Default <code>(str, int)</code> <p>Attribute to get information for.</p> required <p>Returns:</p> Type Description <code>ADRInfo</code> Source code in <code>cdflib/cdfread.py</code> <pre><code>def attinq(self, attribute: Union[str, int]) -&gt; ADRInfo:\n    \"\"\"\n    Get attribute information.\n\n    Parameters\n    ----------\n    attribute : str, int\n        Attribute to get information for.\n\n    Returns\n    -------\n    ADRInfo\n    \"\"\"\n    position = self._first_adr\n    if isinstance(attribute, str):\n        for _ in range(0, self._num_att):\n            name, next_adr = self._read_adr_fast(position)\n            if name.strip().lower() == attribute.strip().lower():\n                return self._read_adr(position)\n\n            position = next_adr\n        raise KeyError(f\"No attribute {attribute}\")\n\n    elif isinstance(attribute, int):\n        if attribute &lt; 0 or attribute &gt; self._num_zvariable:\n            raise KeyError(f\"No attribute {attribute}\")\n        for _ in range(0, attribute):\n            name, next_adr = self._read_adr_fast(position)\n            position = next_adr\n\n        return self._read_adr(position)\n    else:\n        raise ValueError(\"attribute keyword must be a string or integer\")\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF.attinq(attribute)","title":"<code>attribute</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.cdf_info","title":"cdf_info","text":"<pre><code>cdf_info() -&gt; CDFInfo\n</code></pre> <p>Returns basic CDF information.</p> <p>Returns:</p> Type Description <code>CDFInfo</code> Source code in <code>cdflib/cdfread.py</code> <pre><code>def cdf_info(self) -&gt; CDFInfo:\n    \"\"\"\n    Returns basic CDF information.\n\n    Returns\n    -------\n    CDFInfo\n    \"\"\"\n    varnames = self._get_varnames()\n    return CDFInfo(\n        self.file,\n        self._version,\n        self._encoding,\n        self._majority,\n        varnames[0],\n        varnames[1],\n        self._get_attnames(),\n        self._copyright,\n        self._md5,\n        self._num_rdim,\n        self._rdim_sizes,\n        self._compressed,\n    )\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF.globalattsget","title":"globalattsget","text":"<pre><code>globalattsget() -&gt; Dict[str, List[Union[str, ndarray]]]\n</code></pre> <p>Gets all global attributes.</p> <p>This function returns all of the global attribute entries, in a dictionary (in the form of <code>'attribute': {entry: value}</code> pairs) from a CDF.</p> Source code in <code>cdflib/cdfread.py</code> <pre><code>def globalattsget(self) -&gt; Dict[str, List[Union[str, np.ndarray]]]:\n    \"\"\"\n    Gets all global attributes.\n\n    This function returns all of the global attribute entries,\n    in a dictionary (in the form of ``'attribute': {entry: value}``\n    pairs) from a CDF.\n    \"\"\"\n    byte_loc = self._first_adr\n    return_dict: Dict[str, List[Union[str, np.ndarray]]] = {}\n    for _ in range(self._num_att):\n        adr_info = self._read_adr(byte_loc)\n        if adr_info.scope != 1:\n            byte_loc = adr_info.next_adr_loc\n            continue\n        if adr_info.num_gr_entry == 0:\n            byte_loc = adr_info.next_adr_loc\n            continue\n        entries = []\n        aedr_byte_loc = adr_info.first_gr_entry\n        for _ in range(adr_info.num_gr_entry):\n            aedr_info = self._read_aedr(aedr_byte_loc)\n            entryData = aedr_info.entry\n            # This exists to get rid of extraneous numpy arrays\n            if isinstance(entryData, np.ndarray):\n                if len(entryData) == 1:\n                    entryData = entryData[0]\n\n            entries.append(entryData)\n            aedr_byte_loc = aedr_info.next_aedr\n\n        return_dict[adr_info.name] = entries\n        byte_loc = adr_info.next_adr_loc\n\n    return return_dict\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF.varattsget","title":"varattsget","text":"<pre><code>varattsget(variable: Union[str, int]) -&gt; Dict[str, Union[None, str, ndarray]]\n</code></pre> <p>Gets all variable attributes.</p> <p>Unlike attget, which returns a single attribute entry value, this function returns all of the variable attribute entries, in a dictionary (in the form of 'attribute': value pair) for a variable.</p> Source code in <code>cdflib/cdfread.py</code> <pre><code>def varattsget(self, variable: Union[str, int]) -&gt; Dict[str, Union[None, str, np.ndarray]]:\n    \"\"\"\n    Gets all variable attributes.\n\n    Unlike attget, which returns a single attribute entry value,\n    this function returns all of the variable attribute entries,\n    in a dictionary (in the form of 'attribute': value pair) for\n    a variable.\n    \"\"\"\n    if isinstance(variable, int) and self._num_zvariable &gt; 0 and self._num_rvariable &gt; 0:\n        raise ValueError(\"This CDF has both r and z variables. Use variable name\")\n    if isinstance(variable, str):\n        position = self._first_zvariable\n        num_variables = self._num_zvariable\n        for zVar in [True, False]:\n            for _ in range(0, num_variables):\n                name, vdr_next = self._read_vdr_fast(position)\n                if name.strip().lower() == variable.strip().lower():\n                    vdr_info = self._read_vdr(position)\n                    return self._read_varatts(vdr_info.variable_number, zVar)\n                position = vdr_next\n            position = self._first_rvariable\n            num_variables = self._num_rvariable\n        raise ValueError(f\"No variable by this name: {variable}\")\n    elif isinstance(variable, int):\n        if self._num_zvariable &gt; 0:\n            num_variable = self._num_zvariable\n            zVar = True\n        else:\n            num_variable = self._num_rvariable\n            zVar = False\n        if variable &lt; 0 or variable &gt;= num_variable:\n            raise ValueError(f\"No variable by this number: {variable}\")\n        return self._read_varatts(variable, zVar)\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF.varget","title":"varget","text":"<pre><code>varget(variable: Optional[str] = None, epoch: Optional[str] = None, starttime: Optional[epoch_types] = None, endtime: Optional[epoch_types] = None, startrec: int = 0, endrec: Optional[int] = None) -&gt; Union[str, ndarray]\n</code></pre> <p>Returns the variable data.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[str]</code> <p>Variable name to fetch.</p> <code>None</code> <code>int</code> <p>Index of the first record to get.</p> <code>0</code> <code>int</code> <p>Index of the last record to get. All records from startrec to endrec inclusive are fetched.</p> <code>None</code> Notes <p>Variable can be entered either a name or a variable number. By default, it returns a 'numpy.ndarray' or 'list' class object, depending on the data type, with the variable data and its specification.</p> <p>By default, the full variable data is returned. To acquire only a portion of the data for a record-varying variable, either the time or record (0-based) range can be specified. 'epoch' can be used to specify which time variable this variable depends on and is to be searched for the time range. For the ISTP-compliant CDFs, the time variable will come from the attribute 'DEPEND_0' from this variable. The function will automatically search for it thus no need to specify 'epoch'. If either the start or end time is not specified, the possible minimum or maximum value for the specific epoch data type is assumed. If either the start or end record is not specified, the range starts at 0 or/and ends at the last of the written data.</p> <p>The start (and end) time should be presented in a list as: [year month day hour minute second millisec] for CDF_EPOCH [year month day hour minute second millisec microsec nanosec picosec] for CDF_EPOCH16 [year month day hour minute second millisec microsec nanosec] for CDF_TIME_TT2000 If not enough time components are presented, only the last item can have the floating portion for the sub-time components.</p> <p>Note: CDF's CDF_EPOCH16 data type uses 2 8-byte doubles for each data value. In Python, each value is presented as a complex or numpy.complex128.</p> Source code in <code>cdflib/cdfread.py</code> <pre><code>def varget(\n    self,\n    variable: Optional[str] = None,\n    epoch: Optional[str] = None,\n    starttime: Optional[epoch.epoch_types] = None,\n    endtime: Optional[epoch.epoch_types] = None,\n    startrec: int = 0,\n    endrec: Optional[int] = None,\n) -&gt; Union[str, np.ndarray]:\n    \"\"\"\n    Returns the variable data.\n\n    Parameters\n    ----------\n    variable: str\n        Variable name to fetch.\n    startrec: int\n        Index of the first record to get.\n    endrec : int\n        Index of the last record to get. All records from *startrec* to\n        *endrec* inclusive are fetched.\n\n    Notes\n    -----\n    Variable can be entered either\n    a name or a variable number. By default, it returns a\n    'numpy.ndarray' or 'list' class object, depending on the\n    data type, with the variable data and its specification.\n\n    By default, the full variable data is returned. To acquire\n    only a portion of the data for a record-varying variable,\n    either the time or record (0-based) range can be specified.\n    'epoch' can be used to specify which time variable this\n    variable depends on and is to be searched for the time range.\n    For the ISTP-compliant CDFs, the time variable will come from\n    the attribute 'DEPEND_0' from this variable. The function will\n    automatically search for it thus no need to specify 'epoch'.\n    If either the start or end time is not specified,\n    the possible minimum or maximum value for the specific epoch\n    data type is assumed. If either the start or end record is not\n    specified, the range starts at 0 or/and ends at the last of the\n    written data.\n\n    The start (and end) time should be presented in a list as:\n    [year month day hour minute second millisec] for CDF_EPOCH\n    [year month day hour minute second millisec microsec nanosec picosec] for CDF_EPOCH16\n    [year month day hour minute second millisec microsec nanosec] for CDF_TIME_TT2000\n    If not enough time components are presented, only the last item can have the floating\n    portion for the sub-time components.\n\n    Note: CDF's CDF_EPOCH16 data type uses 2 8-byte doubles for each data value.\n    In Python, each value is presented as a complex or numpy.complex128.\n    \"\"\"\n    if isinstance(variable, int) and self._num_zvariable &gt; 0 and self._num_rvariable &gt; 0:\n        raise ValueError(\"This CDF has both r and z variables. \" \"Use variable name instead\")\n\n    if (starttime is not None or endtime is not None) and (startrec != 0 or endrec is not None):\n        raise ValueError(\"Can't specify both time and record range\")\n\n    vdr_info = self.vdr_info(variable)\n    if vdr_info.max_rec &lt; 0:\n        raise ValueError(f\"No records found for variable {variable}\")\n\n    return self._read_vardata(\n        vdr_info,\n        epoch=epoch,\n        starttime=starttime,\n        endtime=endtime,\n        startrec=startrec,\n        endrec=endrec,\n    )\n</code></pre>"},{"location":"cdfread/#cdflib.cdfread.CDF.varget(variable)","title":"<code>variable</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.varget(startrec)","title":"<code>startrec</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.varget(endrec)","title":"<code>endrec</code>","text":""},{"location":"cdfread/#cdflib.cdfread.CDF.varinq","title":"varinq","text":"<pre><code>varinq(variable: str) -&gt; VDRInfo\n</code></pre> <p>Get basic variable information.</p> <p>Returns:</p> Type Description <code>VDRInfo</code> Source code in <code>cdflib/cdfread.py</code> <pre><code>def varinq(self, variable: str) -&gt; VDRInfo:\n    \"\"\"\n    Get basic variable information.\n\n    Returns\n    -------\n    VDRInfo\n    \"\"\"\n    vdr_info = self.vdr_info(variable)\n\n    return VDRInfo(\n        vdr_info.name,\n        vdr_info.variable_number,\n        self._variable_token(vdr_info.section_type),\n        vdr_info.data_type,\n        self._datatype_token(vdr_info.data_type),\n        vdr_info.num_elements,\n        vdr_info.num_dims,\n        vdr_info.dim_sizes,\n        self._sparse_token(vdr_info.sparse),\n        vdr_info.max_rec,\n        vdr_info.record_vary,\n        vdr_info.dim_vary,\n        vdr_info.compression_level,\n        vdr_info.pad,\n        vdr_info.blocking_factor,\n    )\n</code></pre>"},{"location":"cdfread/#sample-usage","title":"Sample Usage","text":"<p>To begin accessing the data within a CDF file, first create a new CDF class. This can be done with the following commands</p> <pre><code>&gt;&gt;&gt; import cdflib\n&gt;&gt;&gt; cdf_file = cdflib.CDF('/path/to/cdf_file.cdf')\n</code></pre> <p>Then, you can call various functions on the variable.</p> <p>For example</p> <pre><code>&gt;&gt;&gt; x = cdf_file.varget(\"NameOfVariable\", startrec = 0, endrec = 150)\n</code></pre> <p>This command will return all data inside of the variable <code>Variable1</code>, from records 0 to 150.</p>"},{"location":"cdfwrite/","title":"cdfwrite","text":""},{"location":"cdfwrite/#cdflib.cdfwrite","title":"cdfwrite","text":"<p>Classes:</p> Name Description <code>CDF</code> <p>Creates an empty CDF file.</p>"},{"location":"cdfwrite/#cdflib.cdfwrite.CDF","title":"CDF","text":"<pre><code>CDF(path: Union[str, Path], cdf_spec: Optional[Dict[str, Any]] = None, delete: bool = False)\n</code></pre> <p>Creates an empty CDF file.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>The path name of the CDF (with or without .cdf extension)</p> required <code>dict</code> <p>The optional specification of the CDF file.</p> <p>The keys for the dictionary are:</p> <ul> <li>['Majority']: 'row_major' or 'column_major', or its   corresponding value. The default is 'column_major'.</li> <li>['Encoding']: Data encoding scheme. See the CDF   documentation about the valid values.   Can be in string or its numeric corresponding value.   The default is 'host', which will be determined when   the script runs.</li> <li>['Checksum']: Whether to set the data validation upon   file creation. The default is False.</li> <li>['rDim_sizes']: The dimensional sizes, applicable   only to rVariables.</li> <li>['Compressed']: Whether to compress the CDF at the file   level. A value of 0-9 or True/False, the   default is 0/False.</li> </ul> <code>None</code> <p>Methods:</p> Name Description <code>close</code> <p>Closes the CDF Class.</p> <code>write_globalattrs</code> <p>Writes the global attributes.</p> <code>write_var</code> <p>Writes a variable, along with variable attributes and data.</p> <code>write_variableattrs</code> <p>Writes a variable's attributes, provided the variable already exists.</p> Source code in <code>cdflib/cdfwrite.py</code> <pre><code>def __init__(self, path: Union[str, Path], cdf_spec: Optional[Dict[str, Any]] = None, delete: bool = False):\n    path = pathlib.Path(path).expanduser()\n\n    major = 1\n    if cdf_spec is not None:\n        major = cdf_spec.get(\"Majority\", major)\n        if isinstance(major, str):\n            major = self._majority_token(major)\n\n        encoding = cdf_spec.get(\"Encoding\", 8)  # default is host\n        if isinstance(encoding, str):\n            encoding = self._encoding_token(encoding)\n\n        checksum = cdf_spec.get(\"Checksum\", False)\n\n        cdf_compression = cdf_spec.get(\"Compressed\", 0)\n        if isinstance(cdf_compression, int):\n            if not 0 &lt;= cdf_compression &lt;= 9:\n                cdf_compression = 0\n        else:\n            cdf_compression = 6 if cdf_compression else 0\n\n        rdim_sizes: Optional[List[int]] = cdf_spec.get(\"rDim_sizes\", None)\n        num_rdim: int = len(rdim_sizes) if rdim_sizes is not None else 0\n\n    else:\n        encoding = 8\n        checksum = False\n        cdf_compression = 0\n        num_rdim = 0\n        rdim_sizes = None\n\n    if major not in [1, 2]:\n        raise RuntimeError(f\"Bad major: {major}\")\n\n    osSystem = pf.system()\n    osMachine = pf.uname()[5]\n    if encoding == 8:\n        if osSystem != \"SunOS\" or osMachine != \"sparc\":\n            self._encoding = self.IBMPC_ENCODING\n        else:\n            self._encoding = self.SUN_ENCODING\n    else:\n        self._encoding = encoding\n        if self._encoding == -1:\n            raise OSError(\"Bad encoding.\")\n    if not isinstance(checksum, bool):\n        raise ValueError(\"Bad checksum.\")\n\n    if path.suffix != \".cdf\":\n        path = path.with_suffix(\".cdf\")\n    if len(str(path)) &gt; self.CDF_PATHNAME_LEN:\n        raise OSError(\"CDF:\", path, \" longer than allowed length.\")\n    if path.is_file():\n        if not delete:\n            raise OSError(\"file: \", path, \" already exists....\\n\", \"Delete it or specify the 'delete=False' option.\")\n        else:\n            path.unlink()\n\n    self.path = path\n\n    self.compressed_file = path.with_suffix(\".tmp\") if cdf_compression &gt; 0 else None\n\n    # Dictionary objects, these contains name, offset, and dimension information\n    self.zvarsinfo: Dict[int, Tuple[str, int, int, List[int], List[bool]]] = {}\n    self.rvarsinfo: Dict[int, Tuple[str, int, int, List[int], List[bool]]] = {}\n\n    # Dictionary object, contains name, offset, and scope (global or variable)\n    self.attrsinfo: Dict[int, Tuple[str, int, int]] = {}\n\n    self.gattrs: List[str] = []  # List of global attributes\n    self.vattrs: List[str] = []  # List of variable attributes\n    self.attrs: List[str] = []  # List of ALL attributes\n    self.zvars: List[str] = []  # List of z variable names\n    self.rvars: List[str] = []  # List of r variable names\n    self.checksum = checksum  # Boolean, whether or not to include the checksum at the end\n    self.compression = cdf_compression  # Compression level (or True/False)\n    self.num_rdim = num_rdim  # Number of r dimensions\n    self.rdim_sizes = rdim_sizes  # Size of r dimensions\n    self.majority = major\n\n    with path.open(\"wb\") as f:\n        f.write(binascii.unhexlify(self.V3magicNUMBER_1))\n        f.write(binascii.unhexlify(self.V3magicNUMBER_2))\n\n        self.cdr_head = self._write_cdr(f, major, self._encoding, checksum)\n        self.gdr_head = self._write_gdr(f)\n        self.offset = f.tell()\n\n    self.is_closed = False\n</code></pre>"},{"location":"cdfwrite/#cdflib.cdfwrite.CDF(path)","title":"<code>path</code>","text":""},{"location":"cdfwrite/#cdflib.cdfwrite.CDF(cdf_spec)","title":"<code>cdf_spec</code>","text":""},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the CDF Class.</p> <pre><code>1. If compression was set, this is where the compressed file is\n   written.\n2. If a checksum is needed, this will place the checksum at the end\n   of the file.\n</code></pre> Source code in <code>cdflib/cdfwrite.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Closes the CDF Class.\n\n        1. If compression was set, this is where the compressed file is\n           written.\n        2. If a checksum is needed, this will place the checksum at the end\n           of the file.\n\n    \"\"\"\n    if self.is_closed:\n        return\n\n    if self.compressed_file is None:\n        with self.path.open(\"rb+\") as f:\n            f.seek(0, 2)\n            eof = f.tell()\n            self._update_offset_value(f, self.gdr_head + 36, 8, eof)\n            if self.checksum:\n                f.write(self._md5_compute(f))\n            self.is_closed = True\n        return\n\n    with self.path.open(\"rb+\") as f:\n        f.seek(0, 2)\n        eof = f.tell()\n        self._update_offset_value(f, self.gdr_head + 36, 8, eof)\n\n        with self.compressed_file.open(\"wb+\") as g:\n            g.write(bytearray.fromhex(self.V3magicNUMBER_1))\n            g.write(bytearray.fromhex(self.V3magicNUMBER_2c))\n            self._write_ccr(f, g, self.compression)\n\n            if self.checksum:\n                g.seek(0, 2)\n                g.write(self._md5_compute(g))\n\n    self.path.unlink()  # NOTE: for Windows this is necessary\n    self.compressed_file.rename(self.path)\n    self.is_closed = True\n</code></pre>"},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_globalattrs","title":"write_globalattrs","text":"<pre><code>write_globalattrs(globalAttrs)\n</code></pre> <p>Writes the global attributes.</p> <p>Parameters:</p> Name Type Description Default <p>Global attribute name(s) and their value(s) pair(s).</p> <p>The value(s) is a dictionary of entry number and value pair(s). For example::</p> <pre><code>globalAttrs={}\nglobalAttrs['Global1']={0: 'Global Value 1'}\nglobalAttrs['Global2']={0: 'Global Value 2'}\n</code></pre> <p>For a non-string value, use a list with the value and its CDF data type. For example::</p> <pre><code>globalAttrs['Global3']={0: [12, 'cdf_int4']}\nglobalAttrs['Global4']={0: [12.34, 'cdf_double']}\n</code></pre> <p>If the data type is not provided, a corresponding CDF data type is assumed::</p> <pre><code>globalAttrs['Global3']={0: 12}     as 'cdf_int4'\nglobalAttrs['Global4']={0: 12.34}  as 'cdf_double'\n</code></pre> <p>CDF allows multi-values for non-string data for an attribute::</p> <pre><code>globalAttrs['Global5']={0: [[12.34,21.43], 'cdf_double']}\n</code></pre> <p>For multi-entries from a global variable, they should be presented in this form::</p> <pre><code>GA6={}\nGA6[0]='abcd'\nGA6[1]=[12, 'cdf_int2']\nGA6[2]=[12.5, 'cdf_float']\nGA6[3]=[[0,1,2], 'cdf_int8']\nglobalAttrs['Global6']=GA6\n....\nf.write_globalattrs(globalAttrs)\n</code></pre> required Source code in <code>cdflib/cdfwrite.py</code> <pre><code>@is_open\ndef write_globalattrs(self, globalAttrs):\n    \"\"\"\n    Writes the global attributes.\n\n    Parameters\n    ----------\n    globalAttrs: dict\n        Global attribute name(s) and their value(s) pair(s).\n\n        The value(s) is a dictionary of entry number and value pair(s).\n        For example::\n\n            globalAttrs={}\n            globalAttrs['Global1']={0: 'Global Value 1'}\n            globalAttrs['Global2']={0: 'Global Value 2'}\n\n        For a non-string value, use a list with the value and its\n        CDF data type. For example::\n\n            globalAttrs['Global3']={0: [12, 'cdf_int4']}\n            globalAttrs['Global4']={0: [12.34, 'cdf_double']}\n\n        If the data type is not provided, a corresponding\n        CDF data type is assumed::\n\n            globalAttrs['Global3']={0: 12}     as 'cdf_int4'\n            globalAttrs['Global4']={0: 12.34}  as 'cdf_double'\n\n        CDF allows multi-values for non-string data for an attribute::\n\n            globalAttrs['Global5']={0: [[12.34,21.43], 'cdf_double']}\n\n        For multi-entries from a global variable, they should be\n        presented in this form::\n\n            GA6={}\n            GA6[0]='abcd'\n            GA6[1]=[12, 'cdf_int2']\n            GA6[2]=[12.5, 'cdf_float']\n            GA6[3]=[[0,1,2], 'cdf_int8']\n            globalAttrs['Global6']=GA6\n            ....\n            f.write_globalattrs(globalAttrs)\n    \"\"\"\n    if not (isinstance(globalAttrs, dict)):\n        raise ValueError(\"Global attribute(s) not in dictionary form\")\n    dataType = None\n    numElems = None\n    with self.path.open(\"rb+\") as f:\n        f.seek(0, 2)  # EOF (appending)\n        for attr, entry in globalAttrs.items():\n            if attr in self.gattrs:\n                raise ValueError(f\"Global attribute: {attr} already exists.\")\n\n            if attr in self.vattrs:\n                logging.warning(f\"Attribute: {attr} already defined as a variable attribute.\")\n                continue\n\n            attrNum, offsetADR = self._write_adr(f, True, attr)\n            entries = 0\n            if entry is None:\n                continue\n            entryNumMaX = -1\n            poffset = -1\n            for entryNum, value in entry.items():\n                if entryNumMaX &lt; entryNum:\n                    entryNumMaX = entryNum\n                if hasattr(value, \"__len__\") and not isinstance(value, str):\n                    if len(value) == 2:\n                        # Check if the second value is a valid data type\n                        value2 = value[1]\n                        dataType = self._datatype_token(value2)\n                        if dataType &gt; 0:\n                            # Data Type found\n                            data = value[0]\n                            if dataType == self.CDF_CHAR or dataType == self.CDF_UCHAR:\n                                if isinstance(data, list) or isinstance(data, tuple):\n                                    logger.warning(\"Invalid global attribute value\")\n                                    return\n                                numElems = len(data)\n                            elif dataType == self.CDF_EPOCH or dataType == self.CDF_EPOCH16 or dataType == self.CDF_TIME_TT2000:\n                                cvalue = []\n                                if isinstance(data, list) or isinstance(data, tuple):\n                                    numElems = len(data)\n                                    for x in range(0, numElems):\n                                        if isinstance(data[x], str):\n                                            cvalue.append(cdfepoch.CDFepoch.parse(data[x]))\n                                        else:\n                                            cvalue.append(data[x])\n                                    data = cvalue\n                                else:\n                                    if isinstance(data, str):\n                                        data = cdfepoch.CDFepoch.parse(data)\n                                    numElems = 1\n                            else:\n                                if isinstance(data, list) or isinstance(data, tuple):\n                                    numElems = len(data)\n                                else:\n                                    numElems = 1\n                        else:\n                            # Data type not found, both values are data.\n                            data = value\n                            numElems, dataType = self._datatype_define(value[0])\n                            numElems = len(value)\n                    else:\n                        # Length greater than 2, so it is all data.\n                        data = value\n                        numElems, dataType = self._datatype_define(value[0])\n                        numElems = len(value)\n                else:\n                    # Just one value\n                    data = value\n                    numElems, dataType = self._datatype_define(value)\n                    if numElems is None:\n                        logger.warning(\"Unknown data\")\n                        return\n\n                offset = self._write_aedr(f, True, attrNum, entryNum, data, dataType, numElems, None)\n                if entries == 0:\n                    # ADR's AgrEDRhead\n                    self._update_offset_value(f, offsetADR + 20, 8, offset)\n                else:\n                    # ADR's ADRnext\n                    self._update_offset_value(f, poffset + 12, 8, offset)\n\n                poffset = offset\n                entries = entries + 1\n            # ADR's NgrEntries\n            self._update_offset_value(f, offsetADR + 36, 4, entries)\n            # ADR's MAXgrEntry\n            self._update_offset_value(f, offsetADR + 40, 4, entryNumMaX)\n</code></pre>"},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_globalattrs(globalAttrs)","title":"<code>globalAttrs</code>","text":""},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_var","title":"write_var","text":"<pre><code>write_var(var_spec, var_attrs=None, var_data=None)\n</code></pre> <p>Writes a variable, along with variable attributes and data.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>The specifications of the variable.</p> <p>The required/optional keys for creating a variable: Required keys:</p> <ul> <li>['Variable']: The name of the variable</li> <li>['Data_Type']: the CDF data type</li> <li>['Num_Elements']: The number of elements. Always 1 the   for numeric type. The char length for string type.</li> <li>['Rec_Vary']: Record variance</li> </ul> <p>For zVariables:</p> <ul> <li>['Dim_Sizes']: The dimensional sizes for zVariables only.   Use [] for 0-dimension. Each and   every dimension is varying for zVariables.</li> </ul> <p>For rVariables:</p> <ul> <li>['Dim_Vary']: The dimensional variances for rVariables only.</li> </ul> <p>Optional keys:</p> <ul> <li>['Var_Type']: Whether the variable is a zVariable or   rVariable. Valid values: \"zVariable\" and   \"rVariable\". The default is \"zVariable\".</li> <li>['Sparse']: Whether the variable has sparse records.   Valid values are \"no_sparse\", \"pad_sparse\",   and \"prev_sparse\". The default is 'no_sparse'.</li> <li>['Compress']: Set the gzip compression level (0 to 9), 0 for   no compression. The default is to compress   with level 6 (done only if the compressed   data is less than the uncompressed data).</li> <li>['Block_Factor']: The blocking factor, the number of   records in a chunk when the variable is compressed.</li> <li>['Pad']: The padded value (in bytes, numpy.ndarray or string)</li> </ul> required <code>dict</code> <p>{attribute:value} pairs.</p> <p>The attribute is the name of a variable attribute. The value can have its data type specified for the numeric data. If not, based on Python's type, a corresponding CDF type is assumed: CDF_INT4 for int, CDF_DOUBLE for float, CDF_EPOCH16 for complex and and CDF_INT8 for long.</p> <p>For example, the following defined attributes will have the same types in the CDF::</p> <pre><code>var_attrs= { 'attr1':  'value1',\n          'attr2':  12.45,\n          'attr3':  [3,4,5],\n          .....\n        }\n</code></pre> <p>With data type (in the list form)::</p> <pre><code>var_attrs= { 'attr1':  'value1',\n          'attr2':  [12.45, 'CDF_DOUBLE'],\n          'attr3':  [[3,4,5], 'CDF_INT4'],\n          .....\n        }\n</code></pre> <code>None</code> <p>The data for the variable. If the variable is a regular variable without sparse records, it must be in a single structure of bytes, or numpy.ndarray for numeric variable, or str or list of strs for string variable. If the variable has sparse records, var_data should be presented in a list/tuple with two elements, the first being a list/tuple that contains the physical record number(s), the second being the variable data in bytes, numpy.ndarray, or a list of strings. Variable data can have just physical records' data (with the same number of records as the first element) or have data from both physical records and virtual records (which with filled data). The var_data has the form::</p> <pre><code>[[rec_#1,rec_#2,rec_#3,...],\n[data_#1,data_#2,data_#3,...]]\n</code></pre> <p>See the sample for its setup.</p> <code>None</code> Source code in <code>cdflib/cdfwrite.py</code> <pre><code>@is_open\ndef write_var(self, var_spec, var_attrs=None, var_data=None):\n    \"\"\"\n    Writes a variable, along with variable attributes and data.\n\n    Parameters\n    ----------\n    var_spec : dict\n        The specifications of the variable.\n\n        The required/optional keys for creating a variable:\n        Required keys:\n\n        - ['Variable']: The name of the variable\n        - ['Data_Type']: the CDF data type\n        - ['Num_Elements']: The number of elements. Always 1 the\n          for numeric type. The char length for string type.\n        - ['Rec_Vary']: Record variance\n\n        For zVariables:\n\n        - ['Dim_Sizes']: The dimensional sizes for zVariables only.\n          Use [] for 0-dimension. Each and\n          every dimension is varying for zVariables.\n\n        For rVariables:\n\n        - ['Dim_Vary']: The dimensional variances for rVariables only.\n\n        Optional keys:\n\n        - ['Var_Type']: Whether the variable is a zVariable or\n          rVariable. Valid values: \"zVariable\" and\n          \"rVariable\". The default is \"zVariable\".\n        - ['Sparse']: Whether the variable has sparse records.\n          Valid values are \"no_sparse\", \"pad_sparse\",\n          and \"prev_sparse\". The default is 'no_sparse'.\n        - ['Compress']: Set the gzip compression level (0 to 9), 0 for\n          no compression. The default is to compress\n          with level 6 (done only if the compressed\n          data is less than the uncompressed data).\n        - ['Block_Factor']: The blocking factor, the number of\n          records in a chunk when the variable is compressed.\n        - ['Pad']: The padded value (in bytes, numpy.ndarray or string)\n\n    var_attrs : dict\n        {attribute:value} pairs.\n\n        The attribute is the name of a variable attribute.\n        The value can have its data type specified for the\n        numeric data. If not, based on Python's type, a\n        corresponding CDF type is assumed: CDF_INT4 for int,\n        CDF_DOUBLE for float, CDF_EPOCH16 for complex and\n        and CDF_INT8 for long.\n\n        For example, the following defined attributes will\n        have the same types in the CDF::\n\n            var_attrs= { 'attr1':  'value1',\n                      'attr2':  12.45,\n                      'attr3':  [3,4,5],\n                      .....\n                    }\n\n        With data type (in the list form)::\n\n            var_attrs= { 'attr1':  'value1',\n                      'attr2':  [12.45, 'CDF_DOUBLE'],\n                      'attr3':  [[3,4,5], 'CDF_INT4'],\n                      .....\n                    }\n\n    var_data :\n        The data for the variable. If the variable is\n        a regular variable without sparse records, it must\n        be in a single structure of bytes, or numpy.ndarray\n        for numeric variable, or str or list of strs for\n        string variable.\n        If the variable has sparse records, var_data should\n        be presented in a list/tuple with two elements,\n        the first being a list/tuple that contains the\n        physical record number(s), the second being the variable\n        data in bytes, numpy.ndarray, or a list of strings. Variable\n        data can have just physical records' data (with the same\n        number of records as the first element) or have data from both\n        physical records and virtual records (which with filled data).\n        The var_data has the form::\n\n            [[rec_#1,rec_#2,rec_#3,...],\n            [data_#1,data_#2,data_#3,...]]\n\n        See the sample for its setup.\n\n    \"\"\"\n    if not isinstance(var_spec, dict):\n        raise TypeError(\"Variable should be in dictionary form.\")\n\n    # Get variable info from var_spec\n    try:\n        dataType = int(var_spec[\"Data_Type\"])\n        numElems = int(var_spec[\"Num_Elements\"])\n        name = var_spec[\"Variable\"]\n        recVary = var_spec[\"Rec_Vary\"]\n    except Exception as e:\n        raise ValueError(\"Missing/invalid required spec for creating variable.\") from e\n    # Get whether or not it is a z variable\n    var_type = var_spec.setdefault(\"Var_Type\", \"zvariable\")\n    if var_type.lower() == \"zvariable\":\n        zVar = True\n    else:\n        var_spec[\"Var_Type\"] = \"rVariable\"\n        zVar = False\n\n    if dataType == self.CDF_CHAR or dataType == self.CDF_UCHAR:\n        if numElems &lt; 1:\n            raise ValueError(\"Invalid Num_Elements for string data type variable\")\n    else:\n        if numElems != 1:\n            raise ValueError(\"Invalid Num_Elements for numeric data type variable\")\n    # If its a z variable, get the dimension info\n    # Otherwise, use r variable info\n    if zVar:\n        try:\n            dimSizes = var_spec[\"Dim_Sizes\"]\n            numDims = len(dimSizes)\n            dimVary = []\n            for _ in range(0, numDims):\n                dimVary.append(True)\n        except Exception:\n            raise ValueError(\"Missing/invalid required spec for creating variable.\")\n    else:\n        dimSizes = self.rdim_sizes\n        numDims = self.num_rdim\n        try:\n            dimVary = var_spec[\"Dim_Vary\"]\n            if len(dimVary) != numDims:\n                raise ValueError(\"Invalid Dim_Vary size for the rVariable.\")\n        except Exception:\n            raise ValueError(\"Missing/invalid required spec for Dim_Vary for rVariable\")\n    # Get Sparseness info\n    sparse = self._sparse_token(var_spec.get(\"Sparse\", \"no_sparse\"))\n    # Get compression info\n    compression = var_spec.get(\"Compress\", 6)\n    if isinstance(compression, int):\n        if not 0 &lt;= compression &lt;= 9:\n            compression = 0\n    else:\n        compression = 6 if compression else 0\n\n    # Get blocking factor\n    blockingfactor = int(var_spec.get(\"Block_Factor\", 1))\n\n    # Get pad value\n    pad = var_spec.get(\"Pad\", None)\n    if hasattr(pad, \"__len__\"):\n        pad = pad[0]\n\n    if name in self.zvars or name in self.rvars:\n        raise ValueError(f\"{name} already exists\")\n\n    with self.path.open(\"rb+\") as f:\n        f.seek(0, 2)  # EOF (appending)\n        varNum, offset = self._write_vdr(\n            f, dataType, numElems, numDims, dimSizes, name, dimVary, recVary, sparse, blockingfactor, compression, pad, zVar\n        )\n        # Update the GDR pointers if needed\n        if zVar:\n            if len(self.zvars) == 1:\n                # GDR's zVDRhead\n                self._update_offset_value(f, self.gdr_head + 20, 8, offset)\n        else:\n            if len(self.rvars) == 1:\n                # GDR's rVDRhead\n                self._update_offset_value(f, self.gdr_head + 12, 8, offset)\n\n        # Write the variable attributes\n        if var_attrs is not None:\n            self._write_var_attrs(f, varNum, var_attrs, zVar)\n\n        # Write the actual data to the file\n        if not (var_data is None):\n            if sparse == 0:\n                varMaxRec = self._write_var_data_nonsparse(\n                    f, zVar, varNum, dataType, numElems, recVary, compression, blockingfactor, var_data\n                )\n            else:\n                notsupport = False\n                if not isinstance(var_data, (list, tuple)):\n                    notsupport = True\n\n                if notsupport or len(var_data) != 2:\n                    logger.warning(\n                        \"Sparse record #s and data are not of list/tuple form:\\n\"\n                        \" [ [rec_#1, rec_#2, rec_#3,    ],\\n\"\n                        \"   [data_#1, data_#2, data_#3, ....] ]\"\n                    )\n                    return\n\n                # Format data into: [[recstart1, recend1, data1],\n                #                   [recstart2,recend2,data2], ...]\n                var_data = self._make_sparse_blocks(var_spec, var_data[0], var_data[1])\n\n                for block in var_data:\n                    varMaxRec = self._write_var_data_sparse(f, zVar, varNum, dataType, numElems, recVary, block)\n            # Update GDR MaxRec if writing an r variable\n            if not zVar:\n                # GDR's rMaxRec\n                f.seek(self.gdr_head + 52)\n                maxRec = int.from_bytes(f.read(4), \"big\", signed=True)\n                if maxRec &lt; varMaxRec:\n                    self._update_offset_value(f, self.gdr_head + 52, 4, varMaxRec)\n</code></pre>"},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_var(var_spec)","title":"<code>var_spec</code>","text":""},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_var(var_attrs)","title":"<code>var_attrs</code>","text":""},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_var(var_data)","title":"<code>var_data</code>","text":""},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_variableattrs","title":"write_variableattrs","text":"<pre><code>write_variableattrs(variableAttrs)\n</code></pre> <p>Writes a variable's attributes, provided the variable already exists.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>Variable attribute name and its entry value pair(s). The entry value is also a dictionary of variable id and value pair(s).  Variable id can be the variable name or its id number in the file. Use write_var function if the variable does not exist. For example::</p> <pre><code>variableAttrs={}\nentries_1={}\nentries_1['var_name_1'] = 'abcd'\nentries_1['var_name_2'] = [12, 'cdf_int4']\n....\nvariableAttrs['attr_name_1']=entries_1\nentries_2={}\nentries_2['var_name_1'] = 'xyz'\nentries_2['var_name_2'] = [[12, 34], 'cdf_int4']\n....\nvariableAttrs['attr_name_2']=entries_2\n....\n....\nf.write_variableattrs(variableAttrs)\n</code></pre> required Source code in <code>cdflib/cdfwrite.py</code> <pre><code>@is_open\ndef write_variableattrs(self, variableAttrs):\n    \"\"\"\n    Writes a variable's attributes, provided the variable already exists.\n\n    Parameters\n    ----------\n    variableAttrs : dict\n        Variable attribute name and its entry value pair(s).\n        The entry value is also a dictionary of variable id and value\n        pair(s).  Variable id can be the variable name or its id number\n        in the file. Use write_var function if the variable does not exist.\n        For example::\n\n            variableAttrs={}\n            entries_1={}\n            entries_1['var_name_1'] = 'abcd'\n            entries_1['var_name_2'] = [12, 'cdf_int4']\n            ....\n            variableAttrs['attr_name_1']=entries_1\n            entries_2={}\n            entries_2['var_name_1'] = 'xyz'\n            entries_2['var_name_2'] = [[12, 34], 'cdf_int4']\n            ....\n            variableAttrs['attr_name_2']=entries_2\n            ....\n            ....\n            f.write_variableattrs(variableAttrs)\n    \"\"\"\n    if not (isinstance(variableAttrs, dict)):\n        raise ValueError(\"Variable attribute(s) not in dictionary form\")\n    dataType = None\n    numElems = None\n    with self.path.open(\"rb+\") as f:\n        f.seek(0, 2)  # EOF (appending)\n        for attr, attrs in variableAttrs.items():\n            if not (isinstance(attr, str)):\n                raise ValueError(\"Attribute name must be a string\")\n                return\n            if attr in self.gattrs:\n                raise ValueError(f\"Variable attribute: {attr}\" + \" is already a global variable\")\n                return\n            if attr in self.vattrs:\n                attrNum = self.vattrs.index(attr)\n                offsetA = self.attrsinfo[attrNum][2]\n            else:\n                attrNum, offsetA = self._write_adr(f, False, attr)\n            entries = 0\n            if attrs is None:\n                continue\n            if not (isinstance(attrs, dict)):\n                raise ValueError(\"An attribute\" \"s attribute(s) not in dictionary form\")\n            entryNumX = -1\n            poffset = -1\n            for entryID, value in attrs.items():\n                if isinstance(entryID, str) and (not (entryID in self.zvars) and not (entryID in self.rvars)):\n                    raise KeyError(f\"{entryID} not found in the CDF\")\n\n                if isinstance(entryID, numbers.Number) and (len(self.zvars) &gt; 0 and len(self.rvars) &gt; 0):\n                    raise ValueError(f\"{entryID} can not be used as the CDF has both zVariables and rVariables\")\n\n                if isinstance(entryID, str):\n                    try:\n                        entryNum = self.zvars.index(entryID)\n                        zVar = True\n                    except Exception:\n                        try:\n                            entryNum = self.rvars.index(entryID)\n                            zVar = False\n                        except Exception:\n                            raise KeyError(f\"{entryID} not found\")\n                else:\n                    entryNum = int(entryID)\n                    if len(self.zvars) &gt; 0 and len(self.rvars) &gt; 0:\n                        raise ValueError(\n                            \"Can not use integer form for variable id as there \", \"are both zVariables and rVaribales\"\n                        )\n                    if len(self.zvars) &gt; 0:\n                        if entryNum &gt;= len(self.zvars):\n                            raise ValueError(\"Variable id: \", entryID, \" not found\")\n                        else:\n                            zVar = True\n                    else:\n                        if entryNum &gt;= len(self.rvars):\n                            raise ValueError(\"Variable id: \", entryID, \" not found\")\n                        else:\n                            zVar = False\n                if entryNum &gt; entryNumX:\n                    entryNumX = entryNum\n                if hasattr(value, \"__len__\") and not isinstance(value, str):\n                    if len(value) == 2:\n                        value2 = value[1]\n                        dataType = self._datatype_token(value2)\n                        if dataType &gt; 0:\n                            data = value[0]\n                            if dataType == self.CDF_CHAR or dataType == self.CDF_UCHAR:\n                                if isinstance(data, list) or isinstance(data, tuple):\n                                    raise ValueError(\"Invalid variable attribute value\")\n                                numElems = len(data)\n                            elif dataType == self.CDF_EPOCH or dataType == self.CDF_EPOCH16 or dataType == self.CDF_TIME_TT2000:\n                                cvalue = []\n                                if isinstance(data, list) or isinstance(data, tuple):\n                                    numElems = len(data)\n                                    for x in range(0, numElems):\n                                        if isinstance(data[x], str):\n                                            avalue = cdfepoch.CDFepoch.parse(data[x])\n                                        else:\n                                            avalue = data[x]\n                                        if dataType == self.CDF_EPOCH16:\n                                            cvalue.append(avalue.real)\n                                            cvalue.append(avalue.imag)\n                                        else:\n                                            cvalue.append(avalue)\n                                            data = cvalue\n                                else:\n                                    if isinstance(data, str):\n                                        data = cdfepoch.CDFepoch.parse(data)\n                                    numElems = 1\n                            else:\n                                if isinstance(data, list) or isinstance(data, tuple):\n                                    numElems = len(data)\n                                else:\n                                    numElems = 1\n                        else:\n                            data = value\n                            numElems, dataType = self._datatype_define(value[0])\n                            numElems = len(value)\n                    else:\n                        data = value\n                        numElems, dataType = self._datatype_define(value[0])\n                        numElems = len(value)\n                else:\n                    data = value\n                    numElems, dataType = self._datatype_define(value)\n                    if numElems is None:\n                        logger.warning(\"Unknown data\")\n                        return\n                offset = self._write_aedr(f, False, attrNum, entryNum, data, dataType, numElems, zVar)\n                if entries == 0:\n                    if zVar:\n                        # ADR's AzEDRhead\n                        self._update_offset_value(f, offsetA + 48, 8, offset)\n                    else:\n                        # ADR's AgrEDRhead\n                        self._update_offset_value(f, offsetA + 20, 8, offset)\n                else:\n                    # ADR's ADRnext\n                    self._update_offset_value(f, poffset + 12, 8, offset)\n                poffset = offset\n                entries = entries + 1\n            if zVar:\n                # ADR's NzEntries\n                self._update_offset_value(f, offsetA + 56, 4, entries)\n                # ADR's MAXzEntry\n                self._update_offset_value(f, offsetA + 60, 4, entryNumX)\n            else:\n                # ADR's NgrEntries\n                self._update_offset_value(f, offsetA + 36, 4, entries)\n                # ADR's MAXgrEntry\n                self._update_offset_value(f, offsetA + 40, 4, entryNumX)\n</code></pre>"},{"location":"cdfwrite/#cdflib.cdfwrite.CDF.write_variableattrs(variableAttrs)","title":"<code>variableAttrs</code>","text":""},{"location":"cdfwrite/#sample-usage","title":"Sample Usage","text":"<pre><code>&gt;&gt;&gt; import cdfwrite\n&gt;&gt;&gt; import cdfread\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt;\n&gt;&gt;&gt; cdf_master = cdfread.CDF('/path/to/master_file.cdf')\n&gt;&gt;&gt; if (cdf_master.file != None):\n&gt;&gt;&gt; # Get the cdf's specification\n&gt;&gt;&gt; info=cdf_master.cdf_info()\n&gt;&gt;&gt; cdf_file=cdfwrite.CDF('/path/to/swea_file.cdf',cdf_spec=info,delete=True)\n&gt;&gt;&gt; if (cdf_file.file == None):\n&gt;&gt;&gt;     cdf_master.close()\n&gt;&gt;&gt;     raise OSError('Problem writing file.... Stop')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Get the global attributes\n&gt;&gt;&gt; globalaAttrs=cdf_master.globalattsget(expand=True)\n&gt;&gt;&gt; # Write the global attributes\n&gt;&gt;&gt; cdf_file.write_globalattrs(globalaAttrs)\n&gt;&gt;&gt; zvars=info['zVariables']\n&gt;&gt;&gt; print('no of zvars=',len(zvars))\n&gt;&gt;&gt; # Loop thru all the zVariables\n&gt;&gt;&gt; for x in range (0, len(zvars)):\n&gt;&gt;&gt;     # Get the variable's specification\n&gt;&gt;&gt;     varinfo=cdf_master.varinq(zvars[x])\n&gt;&gt;&gt;     #print('Z =============&gt;',x,': ', varinfo['Variable'])\n&gt;&gt;&gt;     # Get the variable's attributes\n&gt;&gt;&gt;     varattrs=cdf_master.varattsget(zvars[x], expand=True)\n&gt;&gt;&gt;     if (varinfo['Sparse'].lower() == 'no_sparse'):\n&gt;&gt;&gt;         # A variable with no sparse records... get the variable data\n&gt;&gt;&gt;         vardata=.......\n&gt;&gt;&gt;         # Create the zVariable, write out the attributes and data\n&gt;&gt;&gt;         cdf_file.write_var(varinfo, var_attrs=varattrs, var_data=vardata)\n&gt;&gt;&gt;     else:\n&gt;&gt;&gt;         # A variable with sparse records...\n&gt;&gt;&gt;         # data is in this form [physical_record_numbers, data_values]\n&gt;&gt;&gt;         # physical_record_numbers (0-based) contains the real record\n&gt;&gt;&gt;         # numbers. For example, a variable has only 3 physical records\n&gt;&gt;&gt;         # at [0, 5, 10]:\n&gt;&gt;&gt;         varrecs=[0,5,10]\n&gt;&gt;&gt;         # data_values could contain only the physical records' data or\n&gt;&gt;&gt;         # both the physical and virtual records' data.\n&gt;&gt;&gt;         # For example, a float variable of 1-D with 3 elements with only\n&gt;&gt;&gt;         # 3 physical records at [0,5,10]:\n&gt;&gt;&gt;         # vardata = [[  5.55000000e+01, -1.00000002e+30,  6.65999985e+01],\n&gt;&gt;&gt;         #            [  6.66659973e+02,  7.77770020e+02,  8.88880005e+02],\n&gt;&gt;&gt;         #            [  2.00500000e+02,  2.10600006e+02,  2.20699997e+02]]\n&gt;&gt;&gt;         # Or, with virtual record data embedded in the data:\n&gt;&gt;&gt;         # vardata = [[  5.55000000e+01, -1.00000002e+30,  6.65999985e+01],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [  6.66659973e+02,  7.77770020e+02,  8.88880005e+02],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [ -1.00000002e+30, -1.00000002e+30, -1.00000002e+30],\n&gt;&gt;&gt;         #            [  2.00500000e+02,  2.10600006e+02,  2.20699997e+02]]\n&gt;&gt;&gt;         # Records 1, 2, 3, 4, 6, 7, 8, 9 are all virtual records with pad\n&gt;&gt;&gt;         # data (variable defined with 'pad_sparse').\n&gt;&gt;&gt;         vardata=np.asarray([.,.,.,..])\n&gt;&gt;&gt;         # Create the zVariable, and optionally write out the attributes\n&gt;&gt;&gt;         # and data\n&gt;&gt;&gt;         cdf_file.write_var(varinfo, var_attrs=varattrs,\n&gt;&gt;&gt;                    var_data=[varrecs,vardata])\n&gt;&gt;&gt;    rvars=info['rVariables']\n&gt;&gt;&gt;    print('no of rvars=',len(rvars))\n&gt;&gt;&gt;    # Loop thru all the rVariables\n&gt;&gt;&gt;    for x in range (0, len(rvars)):\n&gt;&gt;&gt;        varinfo=cdf_master.varinq(rvars[x])\n&gt;&gt;&gt;        print('R =============&gt;',x,': ', varinfo['Variable'])\n&gt;&gt;&gt;        varattrs=cdf_master.varattsget(rvars[x], expand=True)\n&gt;&gt;&gt;        if (varinfo['Sparse'].lower() == 'no_sparse'):\n&gt;&gt;&gt;            vardata=.......\n&gt;&gt;&gt;            # Create the rVariable, write out the attributes and data\n&gt;&gt;&gt;            cdf_file.write_var(varinfo, var_attrs=varattrs, var_data=vardata)\n&gt;&gt;&gt;        else:\n&gt;&gt;&gt;            varrecs=[.,.,.,..]\n&gt;&gt;&gt;            vardata=np.asarray([.,.,.,..])\n&gt;&gt;&gt;            cdf_file.write_var(varinfo, var_attrs=varattrs,\n&gt;&gt;&gt;                       var_data=[varrecs,vardata])\n&gt;&gt;&gt; cdf_master.close()\n&gt;&gt;&gt; cdf_file.close()\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#136","title":"1.3.6","text":""},{"location":"changelog/#cdf_to_xarray","title":"cdf_to_xarray","text":"<ul> <li>Stopping uncertainty \"DELTA_VAR\" variables from becoming coordinate variables</li> </ul>"},{"location":"changelog/#cdfwrite","title":"cdfwrite","text":"<ul> <li>newbyteorder call was changed to update with newer version of numpy</li> </ul>"},{"location":"changelog/#134","title":"1.3.4","text":"<p>Performance improvements in cdfwrite</p>"},{"location":"changelog/#cdfwrite_1","title":"cdfwrite","text":"<ul> <li>Endian conversions were using a lot of memory overhead, so we now default to using the built-in numpy array tools</li> </ul>"},{"location":"changelog/#133","title":"1.3.3","text":"<p>Worked through a backlog of bugs</p>"},{"location":"changelog/#xarray_to_cdf","title":"xarray_to_cdf","text":"<ul> <li>Fixed errors that come up with ISTP compliance when a support_data variable has no time variance and depends on another support_data variable</li> <li>Fully remove the deprecated flags of from_unixtime, from_datetime, unixtime_to_cdftt2000, datetime_to_cdftt2000, datetime64_to_cdftt2000</li> <li>Added a check to verify that LABLAXIS/LABL_PTR variables have the same dimensions as the data they need to label</li> </ul>"},{"location":"changelog/#cdfwrite_2","title":"cdfwrite","text":"<ul> <li>Now throw an error when np.uint64 data is given, as it is not a supported data type</li> <li>Fixed a bug that wrote a record's length incorrectly for certain string inputs, causing corrupt CDF files to be generated</li> </ul>"},{"location":"changelog/#cdfread","title":"cdfread","text":"<ul> <li>Fixed a bug where string data was given an extra dimension once read</li> </ul>"},{"location":"changelog/#cdf_to_xarray_1","title":"cdf_to_xarray","text":"<ul> <li>Fixed a bug that caused all data to be squeezed, removing dimensions of size 1</li> </ul>"},{"location":"changelog/#epochs","title":"epochs","text":"<ul> <li>Fixed a bug that occured in CDF_TT2000 to np.datetime64 conversion code, which caused all \"minutes\" to be dropped from the dates if the array contained any dates from before 1972 (which includes all FILLVALs)</li> </ul>"},{"location":"changelog/#132","title":"1.3.2","text":""},{"location":"changelog/#cdfread_1","title":"cdfread","text":"<ul> <li>Updated cdfread to allow anon access from AWS S3</li> </ul>"},{"location":"changelog/#131","title":"1.3.1","text":""},{"location":"changelog/#general-updates","title":"General Updates","text":"<ul> <li>Added tox to serve as the unit testing infrastructure, and changed which unit tests were run (see the github actions to see what exactly is running)</li> <li>Added tests to check future versions of numpy and astropy</li> <li>Added back in the remote data unit tests</li> </ul>"},{"location":"changelog/#xarray_to_cdf_1","title":"xarray_to_cdf","text":"<ul> <li>Added an ISTP check to determine is attribute and variable names are compliant</li> </ul>"},{"location":"changelog/#cdfwrite_3","title":"cdfwrite","text":"<ul> <li>Clearer error message surrounding data type conversions to CDF data types</li> </ul>"},{"location":"changelog/#130","title":"1.3.0","text":""},{"location":"changelog/#general-updates_1","title":"General Updates","text":"<ul> <li>Added .devcontainer to support development of cdflib on github</li> <li>Renamed the master branch to \"main\"</li> <li>Added netcdf4 to the test dependencies</li> <li>unit tests no longer test to_unixtime and from_unixtime conversions.  The loss in the decimal place that occurs from floating point arithmetic causes too many issues.  It may be deprecated functionality in the future.</li> </ul>"},{"location":"changelog/#xarray_to_cdf_2","title":"xarray_to_cdf","text":"<ul> <li>In general, numpy types now have a 1-to-1 correspondence with CDF data types in xarray_to_cdf and cdf_to_xarray. See the documentation for more details</li> <li>Added an ISTP check in xarray_to_cdf to verify that epochs are monotonically increasing</li> <li>Added an ISTP check in xarray_to_cdf to determine if we need a LABL_PTR_1 or LABLAXIS</li> <li>Added ability to manually set the CDF data type of a variable in xarray_to_cdf</li> <li>Added checks in xarray_to_cdf to ensure all CDF_EPOCH16 variables can be cast to a complex128 data type</li> <li>Added automatic conversion of python datetime objects to CDF time variables in xarray_to_cdf, deprecating the from_datetime and datetime_to_cdftt2000 flags</li> <li>Added automatic conversion of numpy datetime64 arrays to CDF time variables in xarray_to_cdf, deprecating the datetime64_to_cdftt2000</li> <li>Automatically populates the FILLVAL attribute with the appropriate ISTP compliant fillvals</li> <li>Ignores variables attributes named \"TIME_ATTRS\" and \"CDF_DATA_TYPE\" from being written to the CDF.  While these are used to modify the function's behavior, they will no longer show up in the CDF file.</li> <li>NaNs and NaTs will automatically be converted to the appropriate FILLVAL.  To keep NaNs in the cdf file, use \"nan_to_fillval=False\"</li> </ul>"},{"location":"changelog/#cdf_to_xarray_2","title":"cdf_to_xarray","text":"<ul> <li>To help avoid some \"lossy\" conversion from CDF files, cdf_to_xarray will append 2 attributes to the variables in the object created. CDF_DATA_TYPE will hold the type of CDF data the variable was if it was not obvious.  TIME_ATTRS contains a list of attributes that represeted time.  These attributes enable better conversion of the xarray object back to a CDF file.  These attributes are also automatically ignored when writing to the CDF file.</li> <li>fillval_to_nan will now automatically convert CDF time variables to datetime64('NaT')</li> </ul>"},{"location":"changelog/#epochs_1","title":"epochs","text":"<ul> <li>to_datetime will now give nano-second precision</li> <li>to_datetime will return all FILLVAL, PAD VALUES, and NaNs to datetime64('NaT')</li> <li>compute(_epoch/_epoch16/_tt2000) returns 0000-01-01T00:00:00.000 for PAD VALUES, keeping with CDF standards</li> </ul>"},{"location":"changelog/#126","title":"1.2.6","text":"<ul> <li>Fixed a bug in cdf_to_xarray that couldn't find dimensions for a variable if there was only one record</li> </ul>"},{"location":"changelog/#125","title":"1.2.5","text":"<ul> <li>Fixed bugs in the xarray conversion code that occured when handling numpy arrays with a length but a dimension of 0.</li> </ul>"},{"location":"changelog/#124","title":"1.2.4","text":"<ul> <li>Added in more logging/error statements to behavior in xarray_to_cdf</li> </ul>"},{"location":"changelog/#123","title":"1.2.3","text":"<ul> <li>xarray_to_cdf now automatically converts FILLVAL attributes to the same type of the primary variable</li> </ul>"},{"location":"changelog/#122","title":"1.2.2","text":"<ul> <li>xarray_to_cdf now automatically converts VALIDMIN/VALIDMAX attributes to the same type of the primary variable</li> </ul>"},{"location":"changelog/#121","title":"1.2.1","text":"<ul> <li>xarray_to_cdf now supports xarrays with datetime64 arrays</li> </ul>"},{"location":"changelog/#120","title":"1.2.0","text":"<ul> <li>Attribute data with a single value is now returned as a Python scalar instead of   a numpy array.</li> <li>Added missing changelog entries for 1.1.1 and 1.1.2.</li> </ul>"},{"location":"changelog/#112","title":"1.1.2","text":"<ul> <li>Fixed a minor bug when writing CDF files.</li> </ul>"},{"location":"changelog/#111","title":"1.1.1","text":"<ul> <li>Added <code>terminate_on_warning</code> and <code>auto_fix_depends</code> options to   <code>~cdflib.xarray.xarray_to_cdf.xarray_to_cdf</code>.   See the docstring for more info.</li> </ul>"},{"location":"changelog/#110","title":"1.1.0","text":"<ul> <li>If the <code>deflate &lt;https://github.com/dcwatson/deflate&gt;</code>_ library is installed   it is now used to decompress data, which can lead to around 2x speedups over   the native gzip Python library.</li> <li>Fixed reading attributes with multiple entries when using <code>cdflib.cdfread.CDF.globalattsget</code>.</li> </ul>"},{"location":"changelog/#105","title":"1.0.5","text":"<ul> <li>Fixed the output of :meth:<code>cdflib.epochs.CDFepoch.compute_tt2000</code> to   be squeezed if a single input is given.</li> <li>Fixed warnings with numpy 1.25.</li> </ul>"},{"location":"changelog/#104","title":"1.0.4","text":"<ul> <li>Fixed issue where multi-dimensional variables were dropped when converting to xarray.</li> <li>Replaced all print and warning statements with a logger, <code>cdflib.logging.logger</code>.</li> </ul>"},{"location":"changelog/#103","title":"1.0.3","text":"<ul> <li>The <code>variable</code> parameter to <code>cdflib.cdfread.CDF.varattsget</code> is no longer optional.   Not specifying it raised an error anyway in previous versions of cdflib.</li> <li>Fixed an error loading CDF files without a pad value set.</li> </ul>"},{"location":"changelog/#102","title":"1.0.2","text":"<p>To make the <code>xarray</code> functionality easier to discover and import, a new <code>cdflib.xarray</code> namespace has been added. This means the recommended way to import the xarray functionality is now <code>from cdflib.xarray import cdf_to_xarray, xarray_to_cdf</code></p>"},{"location":"changelog/#101","title":"1.0.1","text":"<p>To keep <code>astropy</code> and <code>xarray</code> as optional dependencies, <code>cdfastropy</code>, <code>cdf_to_xarray</code>, and <code>xarray_to_cdf</code> are no longer available under <code>cdflib</code>. Instead import them from <code>cdflib.xarray_to_cdf.xarray_to_cdf</code>, <code>cdflib.cdf_to_xarray.cdf_to_xarray</code>, or <code>cdflib.epochs_astropy.CDFAstropy</code>.</p>"},{"location":"changelog/#100","title":"1.0.0","text":"<p>Version 1.0.0 is a new major version for <code>cdflib</code>, and contains a number of breaking changes. These have been made to improve consistency across the package, and make it easier to maintain and build on the package going forward in the future.</p> <p>Although we have tried our best to not introduce new bugs and list all changes below, some things may have slipped through the cracks. If you have any issues, please do not hesitate to open them at https://github.com/MAVENSDC/cdflib/issues.</p>"},{"location":"changelog/#python-support","title":"Python support","text":"<p><code>cdflib</code> is now only tested on Python 3.8, 3.9, 3.10, and 3.11. It may work for older versions of Python, but this is not guarenteed. If you need to use <code>cdflib</code> on an older version of Python, please open an issue to discuss whether the <code>cdflib</code> maintainers can support this.</p>"},{"location":"changelog/#returning-arrays","title":"Returning arrays","text":"<p>All <code>to_np</code> keyword arguments have been removed throughout the library, and the code now behaves as if <code>to_np=True</code> throughout. This change has been made to reduce code omplexity and make maintaining the code easier. If you need outputs as lists, call <code>.tolist()</code> on the output array.</p> <p><code>to_np=True</code> was the deafult in <code>cdfread</code>, so if you weren't specifying it behaviour will not change there. <code>to_np=False</code> was the default in <code>epochs</code>, so if you weren't specifying it there beahviour will change.</p>"},{"location":"changelog/#changes-to-cdf-method-returns","title":"Changes to CDF method returns","text":"<p>Most of the methods that return data from the CDF reader class have had their return types changed from dictionaries to dataclasses. This allows the return type to be more clearly documented (see :ref:<code>dataclasses</code>), for internal checks to be made to make sure data types are consistent, and a nicer representation when the return values are printed.</p> <p>Where previously an item would have been accessed as <code>dict[\"value\"]</code>, items in the dataclasses can be accessed using <code>dataclass.value</code>.</p> <p>The methods that have been updated are:</p> <ul> <li><code>cdflib.cdfread.CDF.vdr_info</code></li> <li><code>cdflib.cdfread.CDF.attinq</code></li> <li><code>cdflib.cdfread.CDF.attget</code></li> <li><code>cdflib.cdfread.CDF.varget</code></li> <li><code>cdflib.cdfread.CDF.varinq</code></li> </ul>"},{"location":"changelog/#other-breaking-changes","title":"Other breaking changes","text":"<ul> <li>The CDF factory class (<code>cdflib.CDF</code>) has been removed, and <code>cdflib.CDF</code>   is now the reader class. This change has been made to prevent potential   confusion when the user makes a mistake in specifying the file to open,   and <code>cdflib</code> would silently create a writer class instead. If you want   to create a CDF writer class, explicitly import <code>cdflib.cdfwrite.CDF</code>   instead.</li> <li><code>cdflib.cdfread.CDF.varget</code> no longer takes an <code>inq</code> argument. Instead   use the new method <code>cdflib.cdfread.CDF.vdr_info</code> to get the VDR info.</li> <li><code>getVersion()</code> methods have been removed throughout the package. Instead   the CDF version can be read from class attributes.</li> <li>Removed <code>cdflib.cdfepochs.CDFepoch.getLeapSecondLastUpdated</code>.   Directly inspect <code>CDFepoch.LTS</code> instead to get the last date at which a   leapsecond was added.</li> <li>The <code>expand</code> keyword argument to <code>cdflib.cdfread.CDF.varget</code> has been removed.   Use <code>CDF.varinq</code> to get variable information instead.</li> <li>The <code>expand</code> keyword argument to <code>CDF.globalattsget</code> and <code>CDF.varattsget</code> has been removed.   Use <code>cdflib.cdfread.CDF.attinq</code> to get attribute information instead.</li> <li>Removed <code>CDF.print_attrs</code></li> <li>The <code>version</code>, <code>release</code>, and <code>increement</code> attributes of <code>CDF</code> have been removed.</li> <li>Removed the <code>record_range_only</code> argument to <code>cdflib.cdfread.CDF.varget</code>.</li> <li>Removed <code>CDF.epochrange</code>. Use <code>cdflib.cdfread.CDF.varinq</code> instead to get the data ranges.</li> </ul>"},{"location":"changelog/#new-features","title":"New features","text":"<ul> <li>Type hints have been added across the majority of the package.</li> </ul>"},{"location":"changelog/#bugfixes","title":"Bugfixes","text":"<ul> <li><code>\"Majority\"</code> is now correctly read from the CDF spec if present.</li> </ul>"},{"location":"dataclasses/","title":"dataclasses","text":""},{"location":"dataclasses/#cdflib.dataclasses","title":"dataclasses","text":"<p>Classes:</p> Name Description <code>AttData</code> <p>Attribute data.</p> <code>CDFInfo</code> <p>CDF information.</p> <code>VDRInfo</code> <p>Variable data record info.</p>"},{"location":"dataclasses/#cdflib.dataclasses.AttData","title":"AttData  <code>dataclass</code>","text":"<pre><code>AttData(Item_Size: int, Data_Type: str, Num_Items: int, Data: Union[Number, str, ndarray])\n</code></pre> <p>Attribute data.</p>"},{"location":"dataclasses/#cdflib.dataclasses.CDFInfo","title":"CDFInfo  <code>dataclass</code>","text":"<pre><code>CDFInfo(CDF: Union[str, Path], Version: str, Encoding: int, Majority: str, rVariables: List[str], zVariables: List[str], Attributes: List[Dict[str, str]], Copyright: str, Checksum: bool, Num_rdim: int, rDim_sizes: List[int], Compressed: bool, LeapSecondUpdate: Optional[int] = None)\n</code></pre> <p>CDF information.</p>"},{"location":"dataclasses/#cdflib.dataclasses.VDRInfo","title":"VDRInfo  <code>dataclass</code>","text":"<pre><code>VDRInfo(Variable: str, Num: int, Var_Type: str, Data_Type: int, Data_Type_Description: str, Num_Elements: int, Num_Dims: int, Dim_Sizes: List[int], Sparse: str, Last_Rec: int, Rec_Vary: int, Dim_Vary: Union[List[int], List[bool]], Compress: int, Pad: Optional[Union[str, ndarray]] = None, Block_Factor: Optional[int] = None)\n</code></pre> <p>Variable data record info.</p>"},{"location":"development/","title":"Developing cdflib","text":""},{"location":"development/#developer-environment","title":"Developer Environment","text":"<p>Typically, development for cdflib is done right on github, using Github Codespaces. Codespaces is ultimately just a slightly fancier devcontainers, so you can also use your local system if you have devcontainers set up. However, CU has weird licensing agreements about Docker Desktop, so I try to avoid it altogether by using Codespaces.  As CU employees, we get 60 free hours of codespace use every month.</p> <p>The setup that Codespaces uses is located in the .devcontainer folder. The devcontainer installs all requirements for cdflib, sets up precommit, and also starts up a virtual desktop. The reason we start a virtual desktop in the devcontainer is in case we want to perform any plotting with matplotlib. The plots will show up within the browser.</p> <p>A new codespace should be created for every PR you are working on. Once the PR is merged, you should delete the codespace (in addition to the branch).</p>"},{"location":"development/#tests","title":"Tests","text":"<p>Unit testing is simply done through pytest. All unit tests are located in the <code>/tests</code> folder.</p>"},{"location":"development/#remote-data","title":"Remote Data","text":"<p>Some of the unit tests run using sample CDF files that need to be downloaded from the MAVEN Science Data Center website. To run these tests in particular, you can use the command:</p> <pre><code>pytest -m remote_data\n</code></pre> <p>However be warned, the test will take approximately 15 minutes to run with the ~20 or so CDF files that have caused issues at various points in development.</p>"},{"location":"development/#working-on-a-ticket","title":"Working on a Ticket","text":"<p>The recommended workflow when you want to work on a ticket:</p> <p>1) Create a new branch (there should be a button to do so on the Github Issue page itself) 2) Start a new Codespace on the branch (again, there should be a button to do so after you create a branch) 3) Make your changes 4) If your changes have made significant alterations to the way CDF files are read/written, run <code>pytest -m remote_data</code> to perform unit tests on CDF files stored on the MAVEN SDC server. 5) Ensure your code passes the pre-commit checks (don't worry, it will tell you if you don't) 6) Create a new PR in the repository, and assign Bryan Harter as a reviewer. 7) Once I have approved changes, perform a \"Squash and Merge\", delete your branch, and delete your Codespace. (All of these should be a button in the page for your specific Pull Request)</p>"},{"location":"development/#documentation","title":"Documentation","text":"<p>Documentation is made using \"mkdocs\" whenever there is a new release of the library. See <code>.github/workflows/docs.yaml</code>.</p> <p>The above script will update the branch <code>gh-pages</code> to build documentation from the markdown files in the \"docs\" folder. The configuration for mkdocs is located in the file <code>mkdocks.yaml</code> in the root directory of the project.</p> <p>To build the documentation you will need to install the documentation requirements using</p> <pre><code>pip install .[docs]\n</code></pre> <p>If you have made changes to the documentation that you would like to check prior to merging, you can serve the documentation to yourself using</p> <pre><code>mkdocs serve\n</code></pre> <p>Note that this will work even on Codespaces. A pop-up will tell you that there is a new port that is open, and you can connect to it.</p>"},{"location":"development/#pre-commit","title":"Pre-commit","text":"<p>This repository is set up to run checks on the code prior to go being committed to git. The setup for pre-commit it in <code>pre-commit-config.yaml</code> in the root of the project. In particular, the key processes that run before a commit are</p> <p>1) <code>Autoflake</code> to remove unused imports and variables. Configuration for autoflake is in the <code>.flake8</code> file in the root directory. 2) <code>isort</code> to keep imports in alphabetical order. 3) <code>Black</code> to restyle the code automatically. 4) <code>mypy</code> to use our static typing to check the code and ensure all types match the functions they are put in to. Configuration for mypy is in the <code>mypy.ini</code> file in the root directory.</p>"},{"location":"development/#pypi-release","title":"PyPI Release","text":"<p>New versions of cdflib are released onto PyPI at https://pypi.org/project/cdflib/.</p> <p>This project lives under LASP's PyPI organization, so all members and admins from that organization can make modifications to the PyPI project. The LASP PyPI organization is run by LASP's Data Systems division.</p> <p>New versions are released to PyPI when a Github release occurs, see the workflow in <code>.github/workflows/pypi-build.yaml</code>. There are no secret keys required; PyPI has been configured to trust deployments from <code>https://github.com/lasp/cdflib/.github/workflows/pypi-build.yaml</code>.</p>"},{"location":"development/#versioning","title":"Versioning","text":"<p>The package version is automatically determined using setuptools_scm, so does not need to be manually incremented when doing a new release.</p>"},{"location":"xarray/","title":"xarray","text":"<p>There are two functions for working with XArray Datasets, one for converting a CDF to a DataSet, and one for going the other way. To use these you need the <code>xarray</code> package installed.</p> <p>These will attempt to determine any ISTP Compliance, and incorporate that into the output.</p>"},{"location":"xarray/#cdflib.xarray.cdf_to_xarray.cdf_to_xarray","title":"cdf_to_xarray","text":"<pre><code>cdf_to_xarray(filename: str, to_datetime: bool = True, to_unixtime: bool = False, fillval_to_nan: bool = False) -&gt; Dataset\n</code></pre> <p>This function converts CDF files into XArray Dataset Objects.</p> <p>Parameters:</p> Name Type Description Default <code> str</code> <p>The path to the CDF file to read</p> required <code>bool</code> <p>Whether or not to convert CDF_EPOCH/EPOCH_16/TT2000 to datetime64, or leave them as is</p> <code>True</code> <code> bool</code> <p>Whether or not to convert CDF_EPOCH/EPOCH_16/TT2000 to unixtime, or leave them as is</p> <code>False</code> <code>bool</code> <p>If True, any data values that match the FILLVAL attribute for a variable will be set to NaN</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dataset</code> <code>Dataset</code> <p>An XArray Dataset object containing all of the data and attributes from the CDF file</p> Example MMS <pre><code>&gt;&gt;&gt; # Import necessary libraries\n&gt;&gt;&gt; import cdflib.xarray\n&gt;&gt;&gt; import xarray as xr\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; import urllib.request\n\n&gt;&gt;&gt; # Download a CDF file\n&gt;&gt;&gt; fname = 'mms2_fgm_srvy_l2_20160809_v4.47.0.cdf'\n&gt;&gt;&gt; url = (\"https://lasp.colorado.edu/maven/sdc/public/data/sdc/web/cdflib_testing/mms2_fgm_srvy_l2_20160809_v4.47.0.cdf\")\n&gt;&gt;&gt; if not os.path.exists(fname):\n&gt;&gt;&gt;     urllib.request.urlretrieve(url, fname)\n\n&gt;&gt;&gt; # Load in and display the CDF file\n&gt;&gt;&gt; mms_data = cdflib.xarray.cdf_to_xarray(\"mms2_fgm_srvy_l2_20160809_v4.47.0.cdf\", to_unixtime=True, fillval_to_nan=True)\n\n&gt;&gt;&gt; # Show off XArray functionality\n\n&gt;&gt;&gt; # Slice the data using built in XArray functions\n&gt;&gt;&gt; mms_data2 = mms_data.isel(dim0=0)\n&gt;&gt;&gt; # Plot the sliced data using built in XArray functions\n&gt;&gt;&gt; mms_data2['mms2_fgm_b_gse_srvy_l2'].plot()\n&gt;&gt;&gt; # Zoom in on the slices data in time using built in XArray functions\n&gt;&gt;&gt; mms_data3 = mms_data2.isel(Epoch=slice(716000,717000))\n&gt;&gt;&gt; # Plot the zoomed in sliced data using built in XArray functionality\n&gt;&gt;&gt; mms_data3['mms2_fgm_b_gse_srvy_l2'].plot()\n</code></pre> Example THEMIS <pre><code>&gt;&gt;&gt; # Import necessary libraries\n&gt;&gt;&gt; import cdflib.xarray\n&gt;&gt;&gt; import xarray as xr\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; import urllib.request\n\n&gt;&gt;&gt; # Download a CDF file\n&gt;&gt;&gt; fname = 'thg_l2_mag_amd_20070323_v01.cdf'\n&gt;&gt;&gt; url = (\"https://lasp.colorado.edu/maven/sdc/public/data/sdc/web/cdflib_testing/thg_l2_mag_amd_20070323_v01.cdf\")\n&gt;&gt;&gt; if not os.path.exists(fname):\n&gt;&gt;&gt;     urllib.request.urlretrieve(url, fname)\n\n&gt;&gt;&gt; # Load in and display the CDF file\n&gt;&gt;&gt; thg_data = cdflib.xarray.cdf_to_xarray(fname, to_unixtime=True, fillval_to_nan=True)\n</code></pre> Processing Steps <pre><code>1. For each variable in the CDF file\n    1. Determine the name of the dimension that spans the data \"records\"\n        - Check if the variable itself might be a dimension\n        - The DEPEND_0 likely points to the approrpiate dimensions\n        - If neither of the above, we create a new dimensions named \"recordX\"\n    2. Determine the name of the other dimensions of the variable, if they exist\n        - Check if the variable name itself might be a dimension\n        - The DEPEND_X probably points to the appropriate dimensions for that variable, so we check those\n        - If either of the above are time varying, the code appends \"_dim\" to the end of the name\n        - If no dimensions are found through the above checks, create a dumension named \"dimX\"\n    3. Gather all attributes that belong to the variable\n    4. Add a few attributes that enable better plotting with built-in xarray functions (name, units, etc)\n    5. Optionally, convert FILLVALs to NaNs in the data\n    6. Optionally, convert CDF_EPOCH/EPOCH16/TT2000 variables to unixtime or datetime\n    7. Create an XArray Variable object using the dimensions determined in steps 1 and 2, the attributes from steps 3 and 4, and then the variable data\n2. Gather all the Variable objects created in the first step, and separate them into data variables or coordinate variables\n3. Gather all global scope attributes in the CDF file\n4. Create an XArray Dataset objects with the data variables, coordinate variables, and global attributes.\n</code></pre> Source code in <code>cdflib/xarray/cdf_to_xarray.py</code> <pre><code>def cdf_to_xarray(filename: str, to_datetime: bool = True, to_unixtime: bool = False, fillval_to_nan: bool = False) -&gt; xr.Dataset:\n    \"\"\"\n    This function converts CDF files into XArray Dataset Objects.\n\n    Parameters\n    ----------\n    filename :  str\n        The path to the CDF file to read\n    to_datetime : bool, optional\n        Whether or not to convert CDF_EPOCH/EPOCH_16/TT2000 to datetime64, or leave them as is\n    to_unixtime :  bool, optional\n        Whether or not to convert CDF_EPOCH/EPOCH_16/TT2000 to unixtime, or leave them as is\n    fillval_to_nan : bool, optional\n        If True, any data values that match the FILLVAL attribute for a variable will be set to NaN\n\n    Returns\n    -------\n    dataset : xarray.Dataset\n        An XArray Dataset object containing all of the data and attributes from the CDF file\n\n    Example MMS\n    -----------\n    ```python\n    &gt;&gt;&gt; # Import necessary libraries\n    &gt;&gt;&gt; import cdflib.xarray\n    &gt;&gt;&gt; import xarray as xr\n    &gt;&gt;&gt; import os\n    &gt;&gt;&gt; import urllib.request\n\n    &gt;&gt;&gt; # Download a CDF file\n    &gt;&gt;&gt; fname = 'mms2_fgm_srvy_l2_20160809_v4.47.0.cdf'\n    &gt;&gt;&gt; url = (\"https://lasp.colorado.edu/maven/sdc/public/data/sdc/web/cdflib_testing/mms2_fgm_srvy_l2_20160809_v4.47.0.cdf\")\n    &gt;&gt;&gt; if not os.path.exists(fname):\n    &gt;&gt;&gt;     urllib.request.urlretrieve(url, fname)\n\n    &gt;&gt;&gt; # Load in and display the CDF file\n    &gt;&gt;&gt; mms_data = cdflib.xarray.cdf_to_xarray(\"mms2_fgm_srvy_l2_20160809_v4.47.0.cdf\", to_unixtime=True, fillval_to_nan=True)\n\n    &gt;&gt;&gt; # Show off XArray functionality\n\n    &gt;&gt;&gt; # Slice the data using built in XArray functions\n    &gt;&gt;&gt; mms_data2 = mms_data.isel(dim0=0)\n    &gt;&gt;&gt; # Plot the sliced data using built in XArray functions\n    &gt;&gt;&gt; mms_data2['mms2_fgm_b_gse_srvy_l2'].plot()\n    &gt;&gt;&gt; # Zoom in on the slices data in time using built in XArray functions\n    &gt;&gt;&gt; mms_data3 = mms_data2.isel(Epoch=slice(716000,717000))\n    &gt;&gt;&gt; # Plot the zoomed in sliced data using built in XArray functionality\n    &gt;&gt;&gt; mms_data3['mms2_fgm_b_gse_srvy_l2'].plot()\n    ```\n\n    Example THEMIS\n    --------------\n    ```python\n    &gt;&gt;&gt; # Import necessary libraries\n    &gt;&gt;&gt; import cdflib.xarray\n    &gt;&gt;&gt; import xarray as xr\n    &gt;&gt;&gt; import os\n    &gt;&gt;&gt; import urllib.request\n\n    &gt;&gt;&gt; # Download a CDF file\n    &gt;&gt;&gt; fname = 'thg_l2_mag_amd_20070323_v01.cdf'\n    &gt;&gt;&gt; url = (\"https://lasp.colorado.edu/maven/sdc/public/data/sdc/web/cdflib_testing/thg_l2_mag_amd_20070323_v01.cdf\")\n    &gt;&gt;&gt; if not os.path.exists(fname):\n    &gt;&gt;&gt;     urllib.request.urlretrieve(url, fname)\n\n    &gt;&gt;&gt; # Load in and display the CDF file\n    &gt;&gt;&gt; thg_data = cdflib.xarray.cdf_to_xarray(fname, to_unixtime=True, fillval_to_nan=True)\n    ```\n\n    Processing Steps\n    ----------------\n        1. For each variable in the CDF file\n            1. Determine the name of the dimension that spans the data \"records\"\n                - Check if the variable itself might be a dimension\n                - The DEPEND_0 likely points to the approrpiate dimensions\n                - If neither of the above, we create a new dimensions named \"recordX\"\n            2. Determine the name of the other dimensions of the variable, if they exist\n                - Check if the variable name itself might be a dimension\n                - The DEPEND_X probably points to the appropriate dimensions for that variable, so we check those\n                - If either of the above are time varying, the code appends \"_dim\" to the end of the name\n                - If no dimensions are found through the above checks, create a dumension named \"dimX\"\n            3. Gather all attributes that belong to the variable\n            4. Add a few attributes that enable better plotting with built-in xarray functions (name, units, etc)\n            5. Optionally, convert FILLVALs to NaNs in the data\n            6. Optionally, convert CDF_EPOCH/EPOCH16/TT2000 variables to unixtime or datetime\n            7. Create an XArray Variable object using the dimensions determined in steps 1 and 2, the attributes from steps 3 and 4, and then the variable data\n        2. Gather all the Variable objects created in the first step, and separate them into data variables or coordinate variables\n        3. Gather all global scope attributes in the CDF file\n        4. Create an XArray Dataset objects with the data variables, coordinate variables, and global attributes.\n    \"\"\"\n\n    if to_datetime and to_unixtime:\n        to_datetime = False\n\n    # Convert the CDF file into a series of dicts, so we don't need to keep reading the file\n    global_attributes, all_variable_attributes, all_variable_data, all_variable_properties = _convert_cdf_to_dicts(\n        filename, to_datetime=to_datetime, to_unixtime=to_unixtime\n    )\n\n    created_vars, depend_dimensions = _generate_xarray_data_variables(\n        all_variable_data, all_variable_attributes, all_variable_properties, fillval_to_nan\n    )\n\n    label_variables = _discover_label_variables(all_variable_attributes, all_variable_properties, all_variable_data)\n    uncertainty_variables = _discover_uncertainty_variables(all_variable_attributes)\n\n    # Determine which dimensions are coordinates vs actual data\n    # Variables are considered coordinates if one of the other dimensions depends on them.\n    # Otherwise, they are considered data coordinates.\n    created_coord_vars: Dict[str, xr.Variable] = {}\n    created_data_vars: Dict[str, xr.Variable] = {}\n    for var_name in created_vars:\n        if var_name in label_variables:\n            # If these are label variables, we'll deal with these later when the DEPEND variables come up\n            continue\n        elif (var_name in depend_dimensions) or (var_name + \"_dim\" in depend_dimensions):\n            # If these are DEPEND variables, add them to the DataSet coordinates\n            created_coord_vars[var_name] = created_vars[var_name]\n            # Check if these coordinate variable have associated labels\n            for lab in label_variables:\n                if label_variables[lab] == var_name:  # Found one! Label \"lab\" covers the dimension \"var_name\"\n                    if len(created_vars[lab].dims) == len(created_vars[var_name].dims):\n                        if created_vars[lab].size != created_vars[var_name].size:\n                            logger.warning(\n                                f\"Warning, label variable {lab} does not match the expected dimension sizes of {var_name}\"\n                            )\n                        else:\n                            created_vars[lab].dims = created_vars[var_name].dims\n                    else:\n                        if created_vars[lab].shape[0] != created_vars[var_name].shape[-1]:  # type: ignore\n                            logger.warning(\n                                f\"Warning, label variable {lab} does not match the expected dimension sizes of {var_name}\"\n                            )\n                        else:\n                            created_vars[lab].dims = (created_vars[var_name].dims[-1],)\n                    # Add the labels to the coordinates as well\n                    created_coord_vars[lab] = created_vars[lab]\n        elif var_name in uncertainty_variables:\n            # If there is an uncertainty variable, link it to the uncertainty along a dimension\n            if created_vars[var_name].size == created_vars[uncertainty_variables[var_name]].size:\n                created_vars[var_name].dims = created_vars[uncertainty_variables[var_name]].dims\n            created_data_vars[var_name] = created_vars[var_name]\n        else:\n            created_data_vars[var_name] = created_vars[var_name]\n\n    # Check that the datasets are valid\n    _verify_dimension_sizes(created_data_vars, created_coord_vars)\n\n    # Create the XArray DataSet Object!\n    return xr.Dataset(data_vars=created_data_vars, coords=created_coord_vars, attrs=global_attributes)\n</code></pre>"},{"location":"xarray/#cdflib.xarray.cdf_to_xarray.cdf_to_xarray(filename)","title":"<code>filename</code>","text":""},{"location":"xarray/#cdflib.xarray.cdf_to_xarray.cdf_to_xarray(to_datetime)","title":"<code>to_datetime</code>","text":""},{"location":"xarray/#cdflib.xarray.cdf_to_xarray.cdf_to_xarray(to_unixtime)","title":"<code>to_unixtime</code>","text":""},{"location":"xarray/#cdflib.xarray.cdf_to_xarray.cdf_to_xarray(fillval_to_nan)","title":"<code>fillval_to_nan</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf","title":"xarray_to_cdf","text":"<pre><code>xarray_to_cdf(xarray_dataset: Dataset, file_name: str, unix_time_to_cdf_time: bool = False, istp: bool = True, terminate_on_warning: bool = False, auto_fix_depends: bool = True, record_dimensions: List[str] = ['record0'], compression: int = 0, nan_to_fillval: bool = True) -&gt; None\n</code></pre> <p>This function converts XArray Dataset objects into CDF files.</p> <p>Parameters:</p> Name Type Description Default <code>Dataset</code> <p>The XArray Dataset object that you'd like to convert into a CDF file</p> required <code>str</code> <p>The path to the place the newly created CDF file</p> required <code>bool</code> <p>Whether or not to assume variables that will become a CDF_EPOCH/EPOCH16/TT2000 are a unix timestamp</p> <code>False</code> <code>bool</code> <p>Whether or not to do checks on the Dataset object to attempt to enforce CDF compliance</p> <code>True</code> <code>bool</code> <p>Whether or not to throw an error when given warnings or to continue trying to make the file</p> <code>False</code> <code>bool</code> <p>Whether or not to automatically add dependencies</p> <code>True</code> <code>list of str</code> <p>If the code cannot determine which dimensions should be made into CDF records, you may provide a list of them here</p> <code>['record0']</code> <code>int</code> <p>The level of compression to gzip the data in the variables.  Default is no compression, standard is 6.</p> <code>0</code> <code>bool</code> <p>Convert all np.nan and np.datetime64('NaT') to the standard CDF FILLVALs.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>Function generates a CDF file</p> Example CDF file from scratch <pre><code>&gt;&gt;&gt; # Import the needed libraries\n&gt;&gt;&gt; from cdflib.xarray import xarray_to_cdf\n&gt;&gt;&gt; import xarray as xr\n&gt;&gt;&gt; import os\n&gt;&gt;&gt; import urllib.request\n\n&gt;&gt;&gt; # Create some fake data\n&gt;&gt;&gt; var_data = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n&gt;&gt;&gt; var_dims = ['epoch', 'direction']\n&gt;&gt;&gt; data = xr.Variable(var_dims, var_data)\n\n&gt;&gt;&gt; # Create fake epoch data\n&gt;&gt;&gt; epoch_data = [1, 2, 3]\n&gt;&gt;&gt; epoch_dims = ['epoch']\n&gt;&gt;&gt; epoch = xr.Variable(epoch_dims, epoch_data)\n\n&gt;&gt;&gt; # Combine the two into an xarray Dataset and export as CDF (this will print out many ISTP warnings)\n&gt;&gt;&gt; ds = xr.Dataset(data_vars={'data': data, 'epoch': epoch})\n&gt;&gt;&gt; xarray_to_cdf(ds, 'hello.cdf')\n\n&gt;&gt;&gt; # Add some global attributes\n&gt;&gt;&gt; global_attributes = {'Project': 'Hail Mary',\n&gt;&gt;&gt;                      'Source_name': 'Thin Air',\n&gt;&gt;&gt;                      'Discipline': 'None',\n&gt;&gt;&gt;                      'Data_type': 'counts',\n&gt;&gt;&gt;                      'Descriptor': 'Midichlorians in unicorn blood',\n&gt;&gt;&gt;                      'Data_version': '3.14',\n&gt;&gt;&gt;                      'Logical_file_id': 'SEVENTEEN',\n&gt;&gt;&gt;                      'PI_name': 'Darth Vader',\n&gt;&gt;&gt;                      'PI_affiliation': 'Dark Side',\n&gt;&gt;&gt;                      'TEXT': 'AHHHHH',\n&gt;&gt;&gt;                      'Instrument_type': 'Banjo',\n&gt;&gt;&gt;                      'Mission_group': 'Impossible',\n&gt;&gt;&gt;                      'Logical_source': ':)',\n&gt;&gt;&gt;                      'Logical_source_description': ':('}\n\n&gt;&gt;&gt; # Lets add a new coordinate variable for the \"direction\"\n&gt;&gt;&gt; dir_data = [1, 2, 3]\n&gt;&gt;&gt; dir_dims = ['direction']\n&gt;&gt;&gt; direction = xr.Variable(dir_dims, dir_data)\n\n&gt;&gt;&gt; # Recreate the Dataset with this new objects, and recreate the CDF\n&gt;&gt;&gt; ds = xr.Dataset(data_vars={'data': data, 'epoch': epoch, 'direction':direction}, attrs=global_attributes)\n&gt;&gt;&gt; os.remove('hello.cdf')\n&gt;&gt;&gt; xarray_to_cdf(ds, 'hello.cdf')\n</code></pre> Example netCDF -&gt; CDF conversion <pre><code>&gt;&gt;&gt; # Download a netCDF file (if needed)\n&gt;&gt;&gt; fname = 'dn_magn-l2-hires_g17_d20211219_v1-0-1.nc'\n&gt;&gt;&gt; url = (\"https://lasp.colorado.edu/maven/sdc/public/data/sdc/web/cdflib_testing/dn_magn-l2-hires_g17_d20211219_v1-0-1.nc\")\n&gt;&gt;&gt; if not os.path.exists(fname):\n&gt;&gt;&gt;     urllib.request.urlretrieve(url, fname)\n\n&gt;&gt;&gt; # Load in the dataset, and set VAR_TYPES attributes (the most important attribute as far as this code is concerned)\n&gt;&gt;&gt; goes_r_mag = xr.load_dataset(\"dn_magn-l2-hires_g17_d20211219_v1-0-1.nc\")\n&gt;&gt;&gt; for var in goes_r_mag:\n&gt;&gt;&gt;     goes_r_mag[var].attrs['VAR_TYPE'] = 'data'\n&gt;&gt;&gt; goes_r_mag['coordinate'].attrs['VAR_TYPE'] = 'support_data'\n&gt;&gt;&gt; goes_r_mag['time'].attrs['VAR_TYPE'] = 'support_data'\n&gt;&gt;&gt; goes_r_mag['time_orbit'].attrs['VAR_TYPE'] = 'support_data'\n\n&gt;&gt;&gt; # Create the CDF file\n&gt;&gt;&gt; xarray_to_cdf(goes_r_mag, 'hello.cdf')\n</code></pre> Processing Steps <pre><code>1. Determines the list of dimensions that represent time-varying dimensions.  These ultimately become the \"records\" of the CDF file\n    - If it is named \"epoch\" or \"epoch_N\", it is considered time-varying\n    - If a variable points to another variable with a DEPEND_0 attribute, it is considered time-varying\n    - If a variable has an attribute of VAR_TYPE equal to \"data\", it is time-varying\n    - If a variable has an attribute of VAR_TYPE equal to \"support_data\" and it is 2 dimensional, it is time-varying\n2. Determine a list of \"dimension\" variables within the Dataset object\n    - These are all coordinates in the dataset that are not time-varying\n    - Additionally, variables that a DEPEND_N attribute points to are also considered dimensions\n3. Optionally, if ISTP=true, automatically add in DEPEND_0/1/2/etc attributes as necessary\n4. Optionally, if ISTP=true, check all variable attributes and global attributes are present\n5. Convert all data into either CDF_INT8, CDF_DOUBLE, CDF_UINT4, or CDF_CHAR\n6. Optionally, convert variables with the name \"epoch\" or \"epoch_N\" to CDF_TT2000\n7. Write all variables and global attributes to the CDF file!\n</code></pre> ISTP Warnings <pre><code>If ISTP=true, these are some of the common things it will check:\n\n- Missing or invalid VAR_TYPE variable attributes\n- DEPEND_N missing from variables\n- DEPEND_N/LABL_PTR/UNIT_PTR/FORM_PTR are pointing to missing variables\n- Missing required global attributes\n- Conflicting global attributes\n- Missing an \"epoch\" dimension\n- DEPEND_N attribute pointing to a variable with uncompatible dimensions\n</code></pre> CDF Data Types <pre><code>All variable data is automatically converted to one of the following CDF types, based on the type of data in the xarray Dataset:\n\n=============  ===============\nNumpy type     CDF Data Type\n=============  ===============\nnp.datetime64  CDF_TIME_TT2000\nnp.int8        CDF_INT1\nnp.int16       CDF_INT2\nnp.int32       CDF_INT4\nnp.int64       CDF_INT8\nnp.float16     CDF_FLOAT\nnp.float32     CDF_FLOAT\nnp.float64     CDF_DOUBLE\nnp.uint8       CDF_UINT1\nnp.uint16      CDF_UINT2\nnp.uint32      CDF_UINT4\nnp.complex_    CDF_EPOCH16\nnp.str_        CDF_CHAR\nnp.bytes_      CDF_CHAR\nobject         CDF_CHAR\ndatetime       CDF_TIME_TT2000\n=============  ===============\n\nIf you want to attempt to cast your data to a different type, you need to add an attribute to your variable called \"CDF_DATA_TYPE\".\nxarray_to_cdf will read this attribute and override the default conversions.  Valid choices are\n\n- Integers: CDF_INT1, CDF_INT2, CDF_INT4, CDF_INT8\n- Unsigned Integers: CDF_UINT1, CDF_UINT2, CDF_UINT4\n- Floating Point: CDF_REAL4, CDF_FLOAT, CDF_DOUBLE, CDF_REAL8\n- Time: CDF_EPOCH, CDF_EPOCH16, CDF_TIME_TT2000\n</code></pre> Source code in <code>cdflib/xarray/xarray_to_cdf.py</code> <pre><code>def xarray_to_cdf(\n    xarray_dataset: xr.Dataset,\n    file_name: str,\n    unix_time_to_cdf_time: bool = False,\n    istp: bool = True,\n    terminate_on_warning: bool = False,\n    auto_fix_depends: bool = True,\n    record_dimensions: List[str] = [\"record0\"],\n    compression: int = 0,\n    nan_to_fillval: bool = True,\n) -&gt; None:\n    \"\"\"\n    This function converts XArray Dataset objects into CDF files.\n\n    Parameters\n    ----------\n    xarray_dataset : xarray.Dataset\n        The XArray Dataset object that you'd like to convert into a CDF file\n    file_name : str\n        The path to the place the newly created CDF file\n    unix_time_to_cdf_time : bool, optional\n        Whether or not to assume variables that will become a CDF_EPOCH/EPOCH16/TT2000 are a unix timestamp\n    istp : bool, optional\n        Whether or not to do checks on the Dataset object to attempt to enforce CDF compliance\n    terminate_on_warning : bool, optional\n        Whether or not to throw an error when given warnings or to continue trying to make the file\n    auto_fix_depends : bool, optional\n        Whether or not to automatically add dependencies\n    record_dimensions : list of str, optional\n        If the code cannot determine which dimensions should be made into CDF records, you may provide a list of them here\n    compression : int, optional\n        The level of compression to gzip the data in the variables.  Default is no compression, standard is 6.\n    nan_to_fillval : bool, optional\n        Convert all np.nan and np.datetime64('NaT') to the standard CDF FILLVALs.\n\n    Returns\n    -------\n    None\n        Function generates a CDF file\n\n    Example CDF file from scratch\n    ------------------------------\n    ```python\n    &gt;&gt;&gt; # Import the needed libraries\n    &gt;&gt;&gt; from cdflib.xarray import xarray_to_cdf\n    &gt;&gt;&gt; import xarray as xr\n    &gt;&gt;&gt; import os\n    &gt;&gt;&gt; import urllib.request\n\n    &gt;&gt;&gt; # Create some fake data\n    &gt;&gt;&gt; var_data = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n    &gt;&gt;&gt; var_dims = ['epoch', 'direction']\n    &gt;&gt;&gt; data = xr.Variable(var_dims, var_data)\n\n    &gt;&gt;&gt; # Create fake epoch data\n    &gt;&gt;&gt; epoch_data = [1, 2, 3]\n    &gt;&gt;&gt; epoch_dims = ['epoch']\n    &gt;&gt;&gt; epoch = xr.Variable(epoch_dims, epoch_data)\n\n    &gt;&gt;&gt; # Combine the two into an xarray Dataset and export as CDF (this will print out many ISTP warnings)\n    &gt;&gt;&gt; ds = xr.Dataset(data_vars={'data': data, 'epoch': epoch})\n    &gt;&gt;&gt; xarray_to_cdf(ds, 'hello.cdf')\n\n    &gt;&gt;&gt; # Add some global attributes\n    &gt;&gt;&gt; global_attributes = {'Project': 'Hail Mary',\n    &gt;&gt;&gt;                      'Source_name': 'Thin Air',\n    &gt;&gt;&gt;                      'Discipline': 'None',\n    &gt;&gt;&gt;                      'Data_type': 'counts',\n    &gt;&gt;&gt;                      'Descriptor': 'Midichlorians in unicorn blood',\n    &gt;&gt;&gt;                      'Data_version': '3.14',\n    &gt;&gt;&gt;                      'Logical_file_id': 'SEVENTEEN',\n    &gt;&gt;&gt;                      'PI_name': 'Darth Vader',\n    &gt;&gt;&gt;                      'PI_affiliation': 'Dark Side',\n    &gt;&gt;&gt;                      'TEXT': 'AHHHHH',\n    &gt;&gt;&gt;                      'Instrument_type': 'Banjo',\n    &gt;&gt;&gt;                      'Mission_group': 'Impossible',\n    &gt;&gt;&gt;                      'Logical_source': ':)',\n    &gt;&gt;&gt;                      'Logical_source_description': ':('}\n\n    &gt;&gt;&gt; # Lets add a new coordinate variable for the \"direction\"\n    &gt;&gt;&gt; dir_data = [1, 2, 3]\n    &gt;&gt;&gt; dir_dims = ['direction']\n    &gt;&gt;&gt; direction = xr.Variable(dir_dims, dir_data)\n\n    &gt;&gt;&gt; # Recreate the Dataset with this new objects, and recreate the CDF\n    &gt;&gt;&gt; ds = xr.Dataset(data_vars={'data': data, 'epoch': epoch, 'direction':direction}, attrs=global_attributes)\n    &gt;&gt;&gt; os.remove('hello.cdf')\n    &gt;&gt;&gt; xarray_to_cdf(ds, 'hello.cdf')\n    ```\n\n    Example netCDF -&gt; CDF conversion\n    --------------------------------\n    ```python\n    &gt;&gt;&gt; # Download a netCDF file (if needed)\n    &gt;&gt;&gt; fname = 'dn_magn-l2-hires_g17_d20211219_v1-0-1.nc'\n    &gt;&gt;&gt; url = (\"https://lasp.colorado.edu/maven/sdc/public/data/sdc/web/cdflib_testing/dn_magn-l2-hires_g17_d20211219_v1-0-1.nc\")\n    &gt;&gt;&gt; if not os.path.exists(fname):\n    &gt;&gt;&gt;     urllib.request.urlretrieve(url, fname)\n\n    &gt;&gt;&gt; # Load in the dataset, and set VAR_TYPES attributes (the most important attribute as far as this code is concerned)\n    &gt;&gt;&gt; goes_r_mag = xr.load_dataset(\"dn_magn-l2-hires_g17_d20211219_v1-0-1.nc\")\n    &gt;&gt;&gt; for var in goes_r_mag:\n    &gt;&gt;&gt;     goes_r_mag[var].attrs['VAR_TYPE'] = 'data'\n    &gt;&gt;&gt; goes_r_mag['coordinate'].attrs['VAR_TYPE'] = 'support_data'\n    &gt;&gt;&gt; goes_r_mag['time'].attrs['VAR_TYPE'] = 'support_data'\n    &gt;&gt;&gt; goes_r_mag['time_orbit'].attrs['VAR_TYPE'] = 'support_data'\n\n    &gt;&gt;&gt; # Create the CDF file\n    &gt;&gt;&gt; xarray_to_cdf(goes_r_mag, 'hello.cdf')\n    ```\n\n    Processing Steps\n    ----------------\n        1. Determines the list of dimensions that represent time-varying dimensions.  These ultimately become the \"records\" of the CDF file\n            - If it is named \"epoch\" or \"epoch_N\", it is considered time-varying\n            - If a variable points to another variable with a DEPEND_0 attribute, it is considered time-varying\n            - If a variable has an attribute of VAR_TYPE equal to \"data\", it is time-varying\n            - If a variable has an attribute of VAR_TYPE equal to \"support_data\" and it is 2 dimensional, it is time-varying\n        2. Determine a list of \"dimension\" variables within the Dataset object\n            - These are all coordinates in the dataset that are not time-varying\n            - Additionally, variables that a DEPEND_N attribute points to are also considered dimensions\n        3. Optionally, if ISTP=true, automatically add in DEPEND_0/1/2/etc attributes as necessary\n        4. Optionally, if ISTP=true, check all variable attributes and global attributes are present\n        5. Convert all data into either CDF_INT8, CDF_DOUBLE, CDF_UINT4, or CDF_CHAR\n        6. Optionally, convert variables with the name \"epoch\" or \"epoch_N\" to CDF_TT2000\n        7. Write all variables and global attributes to the CDF file!\n\n    ISTP Warnings\n    -------------\n        If ISTP=true, these are some of the common things it will check:\n\n        - Missing or invalid VAR_TYPE variable attributes\n        - DEPEND_N missing from variables\n        - DEPEND_N/LABL_PTR/UNIT_PTR/FORM_PTR are pointing to missing variables\n        - Missing required global attributes\n        - Conflicting global attributes\n        - Missing an \"epoch\" dimension\n        - DEPEND_N attribute pointing to a variable with uncompatible dimensions\n\n    CDF Data Types\n    --------------\n        All variable data is automatically converted to one of the following CDF types, based on the type of data in the xarray Dataset:\n\n        =============  ===============\n        Numpy type     CDF Data Type\n        =============  ===============\n        np.datetime64  CDF_TIME_TT2000\n        np.int8        CDF_INT1\n        np.int16       CDF_INT2\n        np.int32       CDF_INT4\n        np.int64       CDF_INT8\n        np.float16     CDF_FLOAT\n        np.float32     CDF_FLOAT\n        np.float64     CDF_DOUBLE\n        np.uint8       CDF_UINT1\n        np.uint16      CDF_UINT2\n        np.uint32      CDF_UINT4\n        np.complex_    CDF_EPOCH16\n        np.str_        CDF_CHAR\n        np.bytes_      CDF_CHAR\n        object         CDF_CHAR\n        datetime       CDF_TIME_TT2000\n        =============  ===============\n\n        If you want to attempt to cast your data to a different type, you need to add an attribute to your variable called \"CDF_DATA_TYPE\".\n        xarray_to_cdf will read this attribute and override the default conversions.  Valid choices are\n\n        - Integers: CDF_INT1, CDF_INT2, CDF_INT4, CDF_INT8\n        - Unsigned Integers: CDF_UINT1, CDF_UINT2, CDF_UINT4\n        - Floating Point: CDF_REAL4, CDF_FLOAT, CDF_DOUBLE, CDF_REAL8\n        - Time: CDF_EPOCH, CDF_EPOCH16, CDF_TIME_TT2000\n\n    \"\"\"\n\n    if os.path.isfile(file_name):\n        _warn_or_except(f\"{file_name} already exists, cannot create CDF file.  Returning...\", terminate_on_warning)\n        return\n\n    # Make a deep copy of the data before continuing\n    dataset = xarray_dataset.copy()\n\n    if nan_to_fillval:\n        _convert_nans_to_fillval(dataset)\n\n    if istp:\n        # This checks all the variable and attribute names to ensure they are ISTP compliant.\n        _validate_varatt_names(dataset, terminate_on_warning)\n\n        # This creates a list of suspected or confirmed label variables\n        _label_checker(dataset, terminate_on_warning)\n\n        # This creates a list of suspected or confirmed dimension variables\n        dim_vars = _dimension_checker(dataset, terminate_on_warning)\n\n        # This creates a list of suspected or confirmed record variables\n        depend_0_vars, time_varying_dimensions = _epoch_checker(dataset, dim_vars, terminate_on_warning)\n\n        depend_0_vars = record_dimensions + depend_0_vars\n        time_varying_dimensions = record_dimensions + time_varying_dimensions\n\n        # After we do the first pass of checking for dimensions and record variables, lets do a second pass to make sure\n        # we've got everything\n        dim_vars = _recheck_dimensions_after_epoch_checker(dataset, time_varying_dimensions, dim_vars, terminate_on_warning)\n\n        # This function will alter the attributes of the data variables if needed\n        dataset = _add_depend_variables_to_dataset(\n            dataset, dim_vars, depend_0_vars, time_varying_dimensions, terminate_on_warning, auto_fix_depends\n        )\n\n        _global_attribute_checker(dataset, terminate_on_warning)\n\n        _variable_attribute_checker(dataset, depend_0_vars, terminate_on_warning)\n    else:\n        depend_0_vars = record_dimensions\n        time_varying_dimensions = record_dimensions\n\n    # Gather the global attributes, write them into the file\n    glob_att_dict: Dict[str, Dict[int, Any]] = {}\n    for ga in dataset.attrs:\n        if hasattr(dataset.attrs[ga], \"__iter__\") and not isinstance(dataset.attrs[ga], str):\n            i = 0\n            glob_att_dict[ga] = {}\n            for entry in dataset.attrs[ga]:\n                glob_att_dict[ga][i] = entry\n                i += 1\n        else:\n            glob_att_dict[ga] = {0: dataset.attrs[ga]}\n\n    x = CDF(file_name)\n    x.write_globalattrs(glob_att_dict)\n\n    # Gather the variables, write them into the file\n    datasets = (dataset, dataset.coords)\n    for d in datasets:\n        for var in d:\n            var = cast(str, var)\n\n            cdf_data_type, cdf_num_elements = _dtype_to_cdf_type(d[var])\n            if cdf_data_type is None or cdf_num_elements is None:\n                continue\n\n            if len(d[var].dims) &gt; 0:\n                if var in time_varying_dimensions or var in depend_0_vars:\n                    dim_sizes = list(d[var].shape[1:])\n                    record_vary = True\n                else:\n                    dim_sizes = list(d[var].shape)\n                    record_vary = False\n            else:\n                dim_sizes = []\n                record_vary = True\n\n            var_data = d[var].data\n\n            cdf_epoch = False\n            cdf_epoch16 = False\n            if \"CDF_DATA_TYPE\" in d[var].attrs:\n                if d[var].attrs[\"CDF_DATA_TYPE\"] == \"CDF_EPOCH\":\n                    cdf_epoch = True\n                elif d[var].attrs[\"CDF_DATA_TYPE\"] == \"CDF_EPOCH16\":\n                    cdf_epoch16 = True\n\n            if _is_datetime_array(d[var].data) or _is_datetime64_array(d[var].data):\n                var_data = _datetime_to_cdf_time(d[var], cdf_epoch=cdf_epoch, cdf_epoch16=cdf_epoch16)\n            elif unix_time_to_cdf_time:\n                if _is_istp_epoch_variable(var) or (\n                    DATATYPES_TO_STRINGS[cdf_data_type] in (\"CDF_EPOCH\", \"CDF_EPOCH16\", \"CDF_TIME_TT2000\")\n                ):\n                    var_data = _unixtime_to_cdf_time(d[var].data, cdf_epoch=cdf_epoch, cdf_epoch16=cdf_epoch16)\n\n            # Grab the attributes from xarray, and attempt to convert VALIDMIN and VALIDMAX to the same data type as the variable\n            var_att_dict = {}\n            for att in d[var].attrs:\n                var_att_dict[att] = d[var].attrs[att]\n                if _is_datetime_array(d[var].attrs[att]) or _is_datetime64_array(d[var].attrs[att]):\n                    att_data = _datetime_to_cdf_time(d[var], cdf_epoch=cdf_epoch, cdf_epoch16=cdf_epoch16, attribute_name=att)\n                    var_att_dict[att] = [att_data, DATATYPES_TO_STRINGS[cdf_data_type]]\n                elif unix_time_to_cdf_time:\n                    if \"TIME_ATTRS\" in d[var].attrs:\n                        if att in d[var].attrs[\"TIME_ATTRS\"]:\n                            if DATATYPES_TO_STRINGS[cdf_data_type] in (\"CDF_EPOCH\", \"CDF_EPOCH16\", \"CDF_TIME_TT2000\"):\n                                att_data = _unixtime_to_cdf_time(d[var].attrs[att], cdf_epoch=cdf_epoch, cdf_epoch16=cdf_epoch16)\n                                var_att_dict[att] = [att_data, DATATYPES_TO_STRINGS[cdf_data_type]]\n                elif (att == \"VALIDMIN\" or att == \"VALIDMAX\" or att == \"FILLVAL\") and istp:\n                    var_att_dict[att] = [d[var].attrs[att], DATATYPES_TO_STRINGS[cdf_data_type]]\n\n            var_spec = {\n                \"Variable\": var,\n                \"Data_Type\": cdf_data_type,\n                \"Num_Elements\": cdf_num_elements,\n                \"Rec_Vary\": record_vary,\n                \"Dim_Sizes\": dim_sizes,\n                \"Compress\": compression,\n            }\n\n            x.write_var(var_spec, var_attrs=var_att_dict, var_data=var_data)\n\n    x.close()\n\n    return\n</code></pre>"},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(xarray_dataset)","title":"<code>xarray_dataset</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(file_name)","title":"<code>file_name</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(unix_time_to_cdf_time)","title":"<code>unix_time_to_cdf_time</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(istp)","title":"<code>istp</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(terminate_on_warning)","title":"<code>terminate_on_warning</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(auto_fix_depends)","title":"<code>auto_fix_depends</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(record_dimensions)","title":"<code>record_dimensions</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(compression)","title":"<code>compression</code>","text":""},{"location":"xarray/#cdflib.xarray.xarray_to_cdf.xarray_to_cdf(nan_to_fillval)","title":"<code>nan_to_fillval</code>","text":""}]}